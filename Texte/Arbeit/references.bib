
@article{lu_comprehensive_2022,
	title = {A comprehensive and fair comparison of two neural operators (with practical extensions) based on {FAIR} data},
	volume = {393},
	issn = {00457825},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782522001207},
	doi = {10.1016/j.cma.2022.114778},
	abstract = {Neural operators can learn nonlinear mappings between function spaces and offer a new simulation paradigm for real-time prediction of complex dynamics for realistic diverse applications as well as for system identification in science and engineering. Herein, we investigate the performance of two neural operators, which have shown promising results so far, and we develop new practical extensions that will make them more accurate and robust and importantly more suitable for industrial-complexity applications. The first neural operator, DeepONet, was published in 2019 (Lu et al., 2019), and its original architecture was based on the universal approximation theorem of Chen \& Chen (1995). The second one, named Fourier Neural Operator or FNO, was published in 2020 (Li et al., 2020), and it is based on parameterizing the integral kernel in the Fourier space. DeepONet is represented by a summation of products of neural networks (NNs), corresponding to the branch NN for the input function and the trunk NN for the output function; both NNs are general architectures, e.g., the branch NN can be replaced with a CNN or a ResNet. According to Kovachki et al. (2021), FNO in its continuous form can be viewed conceptually as a DeepONet with a specific architecture of the branch NN and a trunk NN represented by a trigonometric basis. In order to compare FNO with DeepONet computationally for realistic setups, we develop several extensions of FNO that can deal with complex geometric domains as well as mappings where the input and output function spaces are of different dimensions. We also develop an extended DeepONet with special features that provide inductive bias and accelerate training, and we present a faster implementation of DeepONet with cost comparable to the computational cost of FNO, which is based on the Fast Fourier Transform.},
	language = {en},
	urldate = {2026-02-15},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Lu, Lu and Meng, Xuhui and Cai, Shengze and Mao, Zhiping and Goswami, Somdatta and Zhang, Zhongqiang and Karniadakis, George Em},
	month = apr,
	year = {2022},
	pages = {114778},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\NRT27QUB\\Lu et al. - 2022 - A comprehensive and fair comparison of two neural operators (with practical extensions) based on FAI.pdf:application/pdf},
}

@inproceedings{atallah_novel_2024,
	address = {Orlando, FL},
	title = {A {Novel} {Approach} for {Data}-{Free}, {Physics}-{Informed} {Neural} {Networks} in {Fluid} {Mechanics} {Using} the {Principle} of {Minimum} {Pressure} {Gradient}},
	isbn = {978-1-62410-711-5},
	url = {https://arc.aiaa.org/doi/10.2514/6.2024-2742},
	doi = {10.2514/6.2024-2742},
	language = {en},
	urldate = {2026-02-15},
	booktitle = {{AIAA} {SCITECH} 2024 {Forum}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Atallah, Ahmed and Elmaradny, Abdelrahman and Taha, Haithem E.},
	month = jan,
	year = {2024},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\GELQVHI4\\Atallah et al. - 2024 - A Novel Approach for Data-Free, Physics-Informed Neural Networks in Fluid Mechanics Using the Princi.pdf:application/pdf},
}

@article{rana_scalable_2024,
	title = {A scalable convolutional neural network approach to fluid flow prediction in complex environments},
	volume = {14},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-73529-y},
	doi = {10.1038/s41598-024-73529-y},
	abstract = {We evaluate the capability of convolutional neural networks (CNNs) to predict a velocity field as it relates to fluid flow around various arrangements of obstacles within a two-dimensional, rectangular channel. We base our network architecture on a gated residual U-Net template and train it on velocity fields generated from computational fluid dynamics (CFD) simulations. We then assess the extent to which our model can accurately and efficiently predict steady flows in terms of velocity fields associated with inlet speeds and obstacle configurations not included in our training set. Real-world applications often require fluid-flow predictions in larger and more complex domains that contain more obstacles than used in model training. To address this problem, we propose a method that decomposes a domain into subdomains for which our model can individually and accurately predict the fluid flow, after which we apply smoothness and continuity constraints to reconstruct velocity fields across the whole of the original domain. This piecewise, semicontinuous approach is computationally more efficient than the alternative, which involves generation of CFD datasets required to retrain the model on larger and more spatially complex domains. We introduce a local orientational vector field entropy (LOVE) metric, which quantifies a decorrelation scale for velocity fields in geometric domains with one or more obstacles, and use it to devise a strategy for decomposing complex domains into weakly interacting subsets suitable for application of our modeling approach. We end with an assessment of error propagation across modeled domains of increasing size.},
	language = {en},
	number = {1},
	urldate = {2026-02-15},
	journal = {Scientific Reports},
	author = {Rana, Pratip and Weigand, Timothy M. and Pilkiewicz, Kevin R. and Mayo, Michael L.},
	month = oct,
	year = {2024},
	pages = {23080},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\Q5RRXRUW\\Rana et al. - 2024 - A scalable convolutional neural network approach to fluid flow prediction in complex environments.pdf:application/pdf},
}

@article{koehler_apebench_nodate,
	title = {{APEBench}: {A} {Benchmark} for {Autoregressive} {Neural} {Emulators} of {PDEs}},
	abstract = {We introduce the Autoregressive PDE Emulator Benchmark (APEBench), a comprehensive benchmark suite to evaluate autoregressive neural emulators for solving partial differential equations. APEBench is based on JAX and provides a seamlessly integrated differentiable simulation framework employing efficient pseudo-spectral methods, enabling 46 distinct PDEs across 1D, 2D, and 3D. Facilitating systematic analysis and comparison of learned emulators, we propose a novel taxonomy for unrolled training and introduce a unique identifier for PDE dynamics that directly relates to the stability criteria of classical numerical methods. APEBench enables the evaluation of diverse neural architectures, and unlike existing benchmarks, its tight integration of the solver enables support for differentiable physics training and neural-hybrid emulators. Moreover, APEBench emphasizes rollout metrics to understand temporal generalization, providing insights into the long-term behavior of emulating PDE dynamics. In several experiments, we highlight the similarities between neural emulators and numerical simulators. The code is available at https://github.com/tum-pbs/apebench and APEBench can be installed via pip install apebench.},
	language = {en},
	author = {Koehler, Felix and Niedermayr, Simon and Westermann, Rüdiger and Thuerey, Nils},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\ZGCF94QS\\Koehler et al. - APEBench A Benchmark for Autoregressive Neural Emulators of PDEs.pdf:application/pdf},
}

@article{hu_applying_2023,
	title = {Applying {Physics}-{Informed} {Neural} {Networks} to {Solve} {Navier}–{Stokes} {Equations} for {Laminar} {Flow} around a {Particle}},
	volume = {28},
	issn = {2297-8747},
	url = {https://www.mdpi.com/2297-8747/28/5/102},
	doi = {10.3390/mca28050102},
	abstract = {In recent years, Physics-Informed Neural Networks (PINNs) have drawn great interest among researchers as a tool to solve computational physics problems. Unlike conventional neural networks, which are black-box models that “blindly” establish a correlation between input and output variables using a large quantity of labeled data, PINNs directly embed physical laws (primarily partial differential equations) within the loss function of neural networks. By minimizing the loss function, this approach allows the output variables to automatically satisfy physical equations without the need for labeled data. The Navier–Stokes equation is one of the most classic governing equations in thermal ﬂuid engineering. This study constructs a PINN to solve the Navier–Stokes equations for a 2D incompressible laminar ﬂow problem. Flows passing around a 2D circular particle are chosen as the benchmark case, and an elliptical particle is also examined to enrich the research. The velocity and pressure ﬁelds are predicted by the PINNs, and the results are compared with those derived from Computational Fluid Dynamics (CFD). Additionally, the particle drag force coefﬁcient is calculated to quantify the discrepancy in the results of the PINNs as compared to CFD outcomes. The drag coefﬁcient maintained an error within 10\% across all test scenarios.},
	language = {en},
	number = {5},
	urldate = {2026-02-15},
	journal = {Mathematical and Computational Applications},
	author = {Hu, Beichao and McDaniel, Dwayne},
	month = oct,
	year = {2023},
	pages = {102},
	file = {A Fluid-Dynamical Study of Crystal Settling in:C\:\\Users\\Paul Baselt\\Zotero\\storage\\R3LFU8FB\\A Fluid-Dynamical Study of Crystal Settling in.pdf:application/pdf;PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\R7XYVKXH\\Hu und McDaniel - 2023 - Applying Physics-Informed Neural Networks to Solve Navier–Stokes Equations for Laminar Flow around a.pdf:application/pdf},
}

@article{zhu_bayesian_2018,
	title = {Bayesian {Deep} {Convolutional} {Encoder}-{Decoder} {Networks} for {Surrogate} {Modeling} and {Uncertainty} {Quantification}},
	volume = {366},
	issn = {00219991},
	url = {http://arxiv.org/abs/1801.06879},
	doi = {10.1016/j.jcp.2018.04.018},
	abstract = {We are interested in the development of surrogate models for uncertainty quantification and propagation in problems governed by stochastic PDEs using a deep convolutional encoder-decoder network in a similar fashion to approaches considered in deep learning for image-to-image regression tasks. Since normal neural networks are data intensive and cannot provide predictive uncertainty, we propose a Bayesian approach to convolutional neural nets. A recently introduced variational gradient descent algorithm based on Stein's method is scaled to deep convolutional networks to perform approximate Bayesian inference on millions of uncertain network parameters. This approach achieves state of the art performance in terms of predictive accuracy and uncertainty quantification in comparison to other approaches in Bayesian neural networks as well as techniques that include Gaussian processes and ensemble methods even when the training data size is relatively small. To evaluate the performance of this approach, we consider standard uncertainty quantification benchmark problems including flow in heterogeneous media defined in terms of limited data-driven permeability realizations. The performance of the surrogate model developed is very good even though there is no underlying structure shared between the input (permeability) and output (flow/pressure) fields as is often the case in the image-to-image regression models used in computer vision problems. Studies are performed with an underlying stochastic input dimensionality up to \$4,225\$ where most other uncertainty quantification methods fail. Uncertainty propagation tasks are considered and the predictive output Bayesian statistics are compared to those obtained with Monte Carlo estimates.},
	language = {en},
	urldate = {2026-02-15},
	journal = {Journal of Computational Physics},
	author = {Zhu, Yinhao and Zabaras, Nicholas},
	month = aug,
	year = {2018},
	note = {arXiv:1801.06879 [physics]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
	pages = {415--447},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\76YAR2ZS\\Zhu und Zabaras - 2018 - Bayesian Deep Convolutional Encoder-Decoder Networks for Surrogate Modeling and Uncertainty Quantifi.pdf:application/pdf},
}

@article{kim_deep_2019,
	title = {Deep {Fluids}: {A} {Generative} {Network} for {Parameterized} {Fluid} {Simulations}},
	volume = {38},
	issn = {0167-7055, 1467-8659},
	shorttitle = {Deep {Fluids}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13619},
	doi = {10.1111/cgf.13619},
	abstract = {This paper presents a novel generative model to synthesize ﬂuid simulations from a set of reduced parameters. A convolutional neural network is trained on a collection of discrete, parameterizable ﬂuid simulation velocity ﬁelds. Due to the capability of deep learning architectures to learn representative features of the data, our generative model is able to accurately approximate the training data set, while providing plausible interpolated in-betweens. The proposed generative model is optimized for ﬂuids by a novel loss function that guarantees divergence-free velocity ﬁelds at all times. In addition, we demonstrate that we can handle complex parameterizations in reduced spaces, and advance simulations in time by integrating in the latent space with a second network. Our method models a wide variety of ﬂuid behaviors, thus enabling applications such as fast construction of simulations, interpolation of ﬂuids with different parameters, time re-sampling, latent space simulations, and compression of ﬂuid simulation data. Reconstructed velocity ﬁelds are generated up to 700× faster than re-simulating the data with the underlying CPU solver, while achieving compression rates of up to 1300×.},
	language = {en},
	number = {2},
	urldate = {2026-02-15},
	journal = {Computer Graphics Forum},
	author = {Kim, Byungsoo and Azevedo, Vinicius C. and Thuerey, Nils and Kim, Theodore and Gross, Markus and Solenthaler, Barbara},
	month = may,
	year = {2019},
	pages = {59--70},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\U7Y9JYDF\\Kim et al. - 2019 - Deep Fluids A Generative Network for Parameterized Fluid Simulations.pdf:application/pdf},
}

@inproceedings{guo_convolutional_2016,
	address = {San Francisco California USA},
	title = {Convolutional {Neural} {Networks} for {Steady} {Flow} {Approximation}},
	isbn = {978-1-4503-4232-2},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939738},
	doi = {10.1145/2939672.2939738},
	abstract = {In aerodynamics related design, analysis and optimization problems, ﬂow ﬁelds are simulated using computational ﬂuid dynamics (CFD) solvers. However, CFD simulation is usually a computationally expensive, memory demanding and time consuming iterative process. These drawbacks of CFD limit opportunities for design space exploration and forbid interactive design. We propose a general and ﬂexible approximation model for real-time prediction of non-uniform steady laminar ﬂow in a 2D or 3D domain based on convolutional neural networks (CNNs). We explored alternatives for the geometry representation and the network architecture of CNNs. We show that convolutional neural networks can estimate the velocity ﬁeld two orders of magnitude faster than a GPU-accelerated CFD solver and four orders of magnitude faster than a CPU-based CFD solver at a cost of a low error rate. This approach can provide immediate feedback for real-time design iterations at the early stage of design. Compared with existing approximation models in the aerodynamics domain, CNNs enable an eﬃcient estimation for the entire velocity ﬁeld. Furthermore, designers and engineers can directly apply the CNN approximation model in their design space exploration algorithms without training extra lower-dimensional surrogate models.},
	language = {en},
	urldate = {2026-02-15},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Guo, Xiaoxiao and Li, Wei and Iorio, Francesco},
	month = aug,
	year = {2016},
	pages = {481--490},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\39AMKNFU\\Guo et al. - 2016 - Convolutional Neural Networks for Steady Flow Approximation.pdf:application/pdf},
}

@misc{raonic_convolutional_2023,
	title = {Convolutional {Neural} {Operators} for robust and accurate learning of {PDEs}},
	url = {http://arxiv.org/abs/2302.01178},
	doi = {10.48550/arXiv.2302.01178},
	abstract = {Although very successfully used in conventional machine learning, convolution based neural network architectures – believed to be inconsistent in function space – have been largely ignored in the context of learning solution operators of PDEs. Here, we present novel adaptations for convolutional neural networks to demonstrate that they are indeed able to process functions as inputs and outputs. The resulting architecture, termed as convolutional neural operators (CNOs), is designed specifically to preserve its underlying continuous nature, even when implemented in a discretized form on a computer. We prove a universality theorem to show that CNOs can approximate operators arising in PDEs to desired accuracy. CNOs are tested on a novel suite of benchmarks, encompassing a diverse set of PDEs with possibly multi-scale solutions and are observed to significantly outperform baselines, paving the way for an alternative framework for robust and accurate operator learning. Our code is publicly available at https://github.com/bogdanraonic3/ConvolutionalNeuralOperator.},
	language = {en},
	urldate = {2026-02-15},
	publisher = {arXiv},
	author = {Raonić, Bogdan and Molinaro, Roberto and Ryck, Tim De and Rohner, Tobias and Bartolucci, Francesca and Alaifari, Rima and Mishra, Siddhartha and Bézenac, Emmanuel de},
	month = dec,
	year = {2023},
	note = {arXiv:2302.01178 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\NAAA959V\\Raonić et al. - 2023 - Convolutional Neural Operators for robust and accurate learning of PDEs.pdf:application/pdf},
}

@article{martin_crystal_1988,
	title = {Crystal settling in a vigorously convecting magma chamber},
	volume = {332},
	copyright = {http://www.springer.com/tdm},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/332534a0},
	doi = {10.1038/332534a0},
	language = {en},
	number = {6164},
	urldate = {2026-02-15},
	journal = {Nature},
	author = {Martin, Daniel and Nokes, Roger},
	month = apr,
	year = {1988},
	pages = {534--536},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\9DVJMMUA\\Martin und Nokes - 1988 - Crystal settling in a vigorously convecting magma chamber.pdf:application/pdf},
}

@article{thuerey_deep_2020,
	title = {Deep {Learning} {Methods} for {Reynolds}-{Averaged} {Navier}–{Stokes} {Simulations} of {Airfoil} {Flows}},
	volume = {58},
	issn = {0001-1452, 1533-385X},
	url = {https://arc.aiaa.org/doi/10.2514/1.J058291},
	doi = {10.2514/1.J058291},
	abstract = {With this study, we investigate the accuracy of deep learning models for the inference of Reynolds-Averaged Navier-Stokes solutions. We focus on a modernized Unet architecture and evaluate a large number of trained neural networks with respect to their accuracy for the calculation of pressure and velocity distributions. In particular, we illustrate how training data size and the number of weights inﬂuence the accuracy of the solutions. With our best models, we arrive at a mean relative pressure and velocity error of less than 3\% across a range of previously unseen airfoil shapes. In addition all source code is publicly available in order to ensure reproducibility and to provide a starting point for researchers interested in deep learning methods for physics problems. While this work focuses on RANS solutions, the neural network architecture and learning setup are very generic and applicable to a wide range of PDE boundary value problems on Cartesian grids.},
	language = {en},
	number = {1},
	urldate = {2026-02-15},
	journal = {AIAA Journal},
	author = {Thuerey, Nils and Weißenow, Konstantin and Prantl, Lukas and Hu, Xiangyu},
	month = jan,
	year = {2020},
	pages = {25--36},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\3URMHN53\\Thuerey et al. - 2020 - Deep Learning Methods for Reynolds-Averaged Navier–Stokes Simulations of Airfoil Flows.pdf:application/pdf},
}

@article{ribeiro_deepcfd_nodate,
	title = {{DeepCFD}: {Efficient} {Steady}-{State} {Laminar} {Flow} {Approximation} with {Deep} {Convolutional} {Neural} {Networks}},
	abstract = {Computational Fluid Dynamics (CFD) simulation by the numerical solution of the Navier-Stokes equations is an essential tool in a wide range of applications from engineering design to climate modeling. However, the computational cost and memory demand required by CFD codes may become very high for ﬂows of practical interest, such as in aerodynamic shape optimization. This expense is associated with the complexity of the ﬂuid ﬂow governing equations, which include non-linear partial derivative terms that are of diﬃcult solution, leading to long computational times and limiting the number of hypotheses that can be tested during the process of iterative design. Therefore, we propose DeepCFD: a convolutional neural network (CNN) based model that eﬃciently approximates solutions for the problem of non-uniform steady laminar ﬂows. The proposed model is able to learn complete solutions of the Navier-Stokes equations, for both velocity and pressure ﬁelds, directly from ground-truth data generated using a state-of-the-art CFD code. Using DeepCFD, we found a speedup of up to 3 orders of magnitude compared to the standard CFD approach at a cost of low error rates.},
	language = {en},
	author = {Ribeiro, Mateus Dias and Rehman, Abdul and Ahmed, Sheraz and Dengel, Andreas},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\TKMXS2V6\\Ribeiro et al. - DeepCFD Efficient Steady-State Laminar Flow Approximation with Deep Convolutional Neural Networks.pdf:application/pdf},
}

@article{liu_domain_nodate,
	title = {Domain {Agnostic} {Fourier} {Neural} {Operators}},
	abstract = {Fourier neural operators (FNOs) can learn highly nonlinear mappings between function spaces, and have recently become a popular tool for learning responses of complex physical systems. However, to achieve good accuracy and efficiency, FNOs rely on the Fast Fourier transform (FFT), which is restricted to modeling problems on rectangular domains. To lift such a restriction and permit FFT on irregular geometries as well as topology changes, we introduce domain agnostic Fourier neural operator (DAFNO), a novel neural operator architecture for learning surrogates with irregular geometries and evolving domains. The key idea is to incorporate a smoothed characteristic function in the integral layer architecture of FNOs, and leverage FFT to achieve rapid computations, in such a way that the geometric information is explicitly encoded in the architecture. In our empirical evaluation, DAFNO has achieved state-of-the-art accuracy as compared to baseline neural operator models on two benchmark datasets of material modeling and airfoil simulation. To further demonstrate the capability and generalizability of DAFNO in handling complex domains with topology changes, we consider a brittle material fracture evolution problem. With only one training crack simulation sample, DAFNO has achieved generalizability to unseen loading scenarios and substantially different crack patterns from the trained scenario. Our code and data accompanying this paper are available at https://github.com/ningliu-iga/DAFNO.},
	language = {en},
	author = {Liu, Ning and Jafarzadeh, Siavash and Yu, Yue},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\WAUMIJIA\\Liu et al. - Domain Agnostic Fourier Neural Operators.pdf:application/pdf},
}

@misc{liu_enhancing_2025,
	title = {Enhancing {Fourier} {Neural} {Operators} with {Local} {Spatial} {Features}},
	copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
	url = {https://arxiv.org/abs/2503.17797},
	doi = {10.48550/ARXIV.2503.17797},
	abstract = {Partial Differential Equation (PDE) problems often exhibit strong local spatial structures, and effectively capturing these structures is critical for approximating their solutions. Recently, the Fourier Neural Operator (FNO) has emerged as an efficient approach for solving these PDE problems. By using parametrization in the frequency domain, FNOs can efficiently capture global patterns. However, this approach inherently overlooks the critical role of local spatial features, as frequency-domain parameterized convolutions primarily emphasize global interactions without encoding comprehensive localized spatial dependencies. Although several studies have attempted to address this limitation, their extracted Local Spatial Features (LSFs) remain insufficient, and computational efficiency is often compromised. To address this limitation, we introduce a convolutional neural network (CNN)based feature pre-extractor to capture LSFs directly from input data, resulting in a hybrid architecture termed Conv-FNO. Furthermore, we introduce two novel resizing schemes to make our Conv-FNO resolution invariant. In this work, we focus on demonstrating the effectiveness of incorporating LSFs into FNOs by conducting both a theoretical analysis and extensive numerical experiments. Our findings show that this simple yet impactful modification enhances the representational capacity of FNOs and significantly improves performance on challenging PDE benchmarks.},
	language = {en},
	urldate = {2026-02-15},
	publisher = {arXiv},
	author = {Liu, Chaoyu and Murari, Davide and Liu, Lihao and Li, Yangming and Budd, Chris and Schönlieb, Carola-Bibiane},
	year = {2025},
	note = {Version Number: 2},
	keywords = {FOS: Computer and information sciences, Machine Learning (cs.LG), FOS: Electrical engineering, electronic engineering, information engineering, Image and Video Processing (eess.IV)},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\F2B9YYY5\\Liu et al. - 2025 - Enhancing Fourier Neural Operators with Local Spatial Features.pdf:application/pdf},
}

@article{ma_fast_2022,
	title = {Fast simulation of particulate suspensions enabled by graph neural network},
	volume = {400},
	issn = {00457825},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782522005114},
	doi = {10.1016/j.cma.2022.115496},
	abstract = {Predicting the dynamic behaviors of particles in suspension subject to hydrodynamic interaction (HI) and external drive can be critical for many applications. By harvesting advanced deep learning techniques, the present work introduces a new framework, hydrodynamic interaction graph neural network (HIGNN), for inferring and predicting the particles’ dynamics in Stokes suspensions. It overcomes the limitations of traditional approaches in computational efficiency, accuracy, and/or transferability. In particular, by uniting the data structure represented by a graph and the neural networks with learnable parameters, the HIGNN constructs surrogate modeling for the mobility tensor of particles which is the key to predicting the dynamics of particles subject to HI and external forces. To account for the many-body nature of HI, we generalize the state-of-the-art GNN by introducing higher-order connectivity into the graph and the corresponding convolutional operation. For training the HIGNN, we only need the data for a small number of particles in the domain of interest, and hence the training cost can be maintained low. Once constructed, the HIGNN permits fast predictions of the particles’ velocities and is transferable to suspensions of different numbers/concentrations of particles in the same domain and to any external forcing. It has the ability to accurately capture both the long-range HI and short-range lubrication effects. We demonstrate the accuracy, efficiency, and transferability of the proposed HIGNN framework in a variety of systems. The requirement on computing resource is minimum: most simulations only require a desktop with one GPU; the simulations for a large suspension of 100,000 particles call for up to 6 GPUs.},
	language = {en},
	urldate = {2026-02-15},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Ma, Zhan and Ye, Zisheng and Pan, Wenxiao},
	month = oct,
	year = {2022},
	pages = {115496},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\MIRK58WT\\Ma et al. - 2022 - Fast simulation of particulate suspensions enabled by graph neural network.pdf:application/pdf},
}

@misc{xiao_fourier_2024,
	title = {Fourier neural operator based fluid-structure interaction for predicting the vesicle dynamics},
	url = {http://arxiv.org/abs/2401.02311},
	doi = {10.48550/arXiv.2401.02311},
	abstract = {Solving complex fluid-structure interaction (FSI) problems, characterized by nonlinear partial differential equations, is crucial in various scientific and engineering applications. Traditional computational fluid dynamics (CFD) solvers are insufficient to meet the growing requirements for large-scale and long-period simulations. Fortunately, the rapid advancement in neural networks, especially neural operator learning mappings between function spaces, has introduced novel approaches to tackle these challenges via data-driven modeling. In this paper, we propose a Fourier neural operator-based fluid-structure interaction solver (FNObased FSI solver) for efficient simulation of FSI problems, where the solid solver based on the finite difference method is seamlessly integrated with the Fourier neural operator to predict incompressible flow using the immersed boundary method. We analyze the performance of the FNO-based FSI solver in the following three situations: training data with or without the steady state, training method with one-step label or multi-step labels, and prediction in interpolation or extrapolation. We find that the best performance for interpolation is achieved by training the operator with multi-step labels using steady-state data. Finally, we train the FNO-based FSI solver using this optimal training method and apply it to vesicle dynamics. The results show that the FNO-based FSI solver is capable of capturing the variations in the fluid and the vesicle.},
	language = {en},
	urldate = {2026-02-15},
	publisher = {arXiv},
	author = {Xiao, Wang and Gao, Ting and Liu, Kai and Duan, Jinqiao and Zhao, Meng},
	month = jan,
	year = {2024},
	note = {arXiv:2401.02311 [math]},
	keywords = {Mathematics - Dynamical Systems},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\2DTBQ9LV\\Xiao et al. - 2024 - Fourier neural operator based fluid-structure interaction for predicting the vesicle dynamics.pdf:application/pdf},
}

@misc{li_fourier_2021,
	title = {Fourier {Neural} {Operator} for {Parametric} {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2010.08895},
	doi = {10.48550/arXiv.2010.08895},
	abstract = {The classical development of neural networks has primarily focused on learning mappings between ﬁnite-dimensional Euclidean spaces. Recently, this has been generalized to neural operators that learn mappings between function spaces. For partial differential equations (PDEs), neural operators directly learn the mapping from any functional parametric dependence to the solution. Thus, they learn an entire family of PDEs, in contrast to classical methods which solve one instance of the equation. In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efﬁcient architecture. We perform experiments on Burgers’ equation, Darcy ﬂow, and Navier-Stokes equation. The Fourier neural operator is the ﬁrst ML-based method to successfully model turbulent ﬂows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional PDE solvers. Additionally, it achieves superior accuracy compared to previous learning-based solvers under ﬁxed resolution.},
	language = {en},
	urldate = {2026-02-15},
	publisher = {arXiv},
	author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
	month = may,
	year = {2021},
	note = {arXiv:2010.08895 [cs]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\S3L3CX27\\Li et al. - 2021 - Fourier Neural Operator for Parametric Partial Differential Equations.pdf:application/pdf},
}

@article{li_fourier_nodate,
	title = {Fourier {Neural} {Operator} with {Learned} {Deformations} for {PDEs} on {General} {Geometries}},
	abstract = {Deep learning surrogate models have shown promise in solving partial differential equations (PDEs). Among them, the Fourier neural operator (FNO) achieves good accuracy, and is significantly faster compared to numerical solvers, on a variety of PDEs, such as fluid flows. However, the FNO uses the Fast Fourier transform (FFT), which is limited to rectangular domains with uniform grids. In this work, we propose a new framework, viz., Geo-FNO, to solve PDEs on arbitrary geometries. Geo-FNO learns to deform the input (physical) domain, which may be irregular, into a latent space with a uniform grid. The FNO model with the FFT is applied in the latent space. The resulting Geo-FNO model has both the computation efficiency of FFT and the flexibility of handling arbitrary geometries. Our Geo-FNO is also flexible in terms of its input formats, viz., point clouds, meshes, and design parameters are all valid inputs. We consider a variety of PDEs such as the Elasticity, Plasticity, Euler’s, and Navier-Stokes equations, and both forward modeling and inverse design problems. Comprehensive cost-accuracy experiments show that Geo-FNO is 105 times faster than the standard numerical solvers and twice more accurate compared to direct interpolation on existing ML-based PDE solvers such as the standard FNO.},
	language = {en},
	author = {Li, Zongyi and Huang, Daniel Zhengyu and Liu, Burigede},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\GIRELEU3\\Li et al. - Fourier Neural Operator with Learned Deformations for PDEs on General Geometries.pdf:application/pdf},
}

@article{morimoto_generalization_2022,
	title = {Generalization techniques of neural networks for fluid flow estimation},
	volume = {34},
	issn = {0941-0643, 1433-3058},
	url = {https://link.springer.com/10.1007/s00521-021-06633-z},
	doi = {10.1007/s00521-021-06633-z},
	abstract = {We demonstrate several techniques to encourage practical uses of neural networks for ﬂuid ﬂow estimation. In the present paper, three perspectives which are remaining challenges for applications of machine learning to ﬂuid dynamics are considered: 1. interpretability of machine-learned results, 2. bulking out of training data, and 3. generalizability of neural networks. For the interpretability, we ﬁrst demonstrate two methods to observe the internal procedure of neural networks, i.e., visualization of hidden layers and application of gradient-weighted class activation mapping (Grad-CAM), applied to canonical ﬂuid ﬂow estimation problems—(1) drag coefﬁcient estimation of a cylinder wake and (2) velocity estimation from particle images. It is exempliﬁed that both approaches can successfully tell us evidences of the great capability of machine learning-based estimations. We then utilize some techniques to bulk out training data for super-resolution analysis and temporal prediction for cylinder wake and NOAA sea surface temperature data to demonstrate that sufﬁcient training of neural networks with limited amount of training data can be achieved for ﬂuid ﬂow problems. The generalizability of machine learning model is also discussed by accounting for the perspectives of inter/extrapolation of training data, considering super-resolution of wakes behind two parallel cylinders. We ﬁnd that various ﬂow patterns generated by complex interaction between two cylinders can be reconstructed well, even for the test conﬁgurations regarding the distance factor. The present paper can be a signiﬁcant step toward practical uses of neural networks for both laminar and turbulent ﬂow problems.},
	language = {en},
	number = {5},
	urldate = {2026-02-15},
	journal = {Neural Computing and Applications},
	author = {Morimoto, Masaki and Fukami, Kai and Zhang, Kai and Fukagata, Koji},
	month = mar,
	year = {2022},
	pages = {3647--3669},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\SP8JIJUY\\Morimoto et al. - 2022 - Generalization techniques of neural networks for fluid flow estimation.pdf:application/pdf},
}

@article{verhoeven_numerical_2009,
	title = {A numerical method for investigating crystal settling in convecting magma chambers},
	volume = {10},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {1525-2027, 1525-2027},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2009GC002509},
	doi = {10.1029/2009GC002509},
	abstract = {Magma chambers can be considered as thermochemically driven convection systems. We present a new numerical method that describes the movement of crystallized minerals in terms of active spherical particles in a convecting magma that is represented by an infinite Prandtl number fluid. The main part focuses on the results we obtained. A finite volume thermochemical convection model for two and three dimensions and a discrete element method, which is used to model granular material, are combined. The new model is validated with floating experiments using particles of different densities and an investigation of single and multiparticle settling velocities. The resulting velocities are compared with theoretical predictions by Stokes's law and a hindered settling function for the multiparticle system. Two fundamental convection regimes are identified in the parameter space that is spanned by the Rayleigh number and the chemical Rayleigh number, which is a measure for the density of the particles. We define the T regime that is dominated by thermal convection. Here the thermal driving force is strong enough to keep all particles in suspension. As the particles get denser, they start settling to the ground, which results in a C regime. The C regime is characterized by the existence of a sediment layer with particle‐rich material and a suspension layer with few particles. It is shown that the presence of particles can reduce the vigor of thermal convection. In the frame of a parameter study we discuss the change between the regimes that is systematically investigated. We show that the so‐called TC transition fits a power law. Furthermore, we investigate the settling behavior of the particles in vigorous thermal convection, which can be linked to crystal settling in magma chambers. We develop an analytical settling law that describes the number of settled particles against time and show that the results fit the observations from numerical and laboratory experiments.},
	language = {en},
	number = {12},
	urldate = {2026-02-15},
	journal = {Geochemistry, Geophysics, Geosystems},
	author = {Verhoeven, J. and Schmalzl, J.},
	month = dec,
	year = {2009},
	pages = {2009GC002509},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\C8NMHK7H\\Verhoeven und Schmalzl - 2009 - A numerical method for investigating crystal settling in convecting magma chambers.pdf:application/pdf},
}

@article{oldenburg_geometry_2022,
	title = {Geometry aware physics informed neural network surrogate for solving {Navier}–{Stokes} equation ({GAPINN})},
	volume = {9},
	issn = {2213-7467},
	url = {https://amses-journal.springeropen.com/articles/10.1186/s40323-022-00221-z},
	doi = {10.1186/s40323-022-00221-z},
	abstract = {Many real world problems involve fluid flow phenomena, typically be described by the Navier–Stokes equations. The Navier–Stokes equations are partial differential equations (PDEs) with highly nonlinear properties. Currently mostly used methods solve this dif‑ferential equation by discretizing geometries. In the field of fluid mechanics the finite volume method (FVM) is widely used for numerical flow simulation, so‑called com‑putational fluid dynamics (CFD). Due to high computational costs and cumbersome generation of the discretization they are not widely used in real time applications. Our presented work focuses on advancing PDE‑constrained deep learning frameworks for more real‑world applications with irregular geometries without parameterization. We present a Deep Neural Network framework that generate surrogates for non‑geometric boundaries by data free solely physics driven training, by minimizing the residuals of the governing PDEs (i.e., conservation laws) so that no computationally expensive CFD simulation data is needed. We named this method geometry aware physics informed neural network—GAPINN. The framework involves three network types. The first network reduces the dimensions of the irregular geometries to a latent representation. In this work we used a Variational‑Auto‑Encoder (VAE) for this task. We proposed the concept of using this latent representation in combination with spatial coordinates as input for PINNs. Using PINNs we showed that it is possible to train a surrogate model purely driven on the reduction of the residuals of the underlying PDE for irregular non‑parametric geometries. Furthermore, we showed the way of designing a boundary constraining network (BCN) to hardly enforce boundary conditions during training of the PINN. We evaluated this concept on test cases in the fields of biofluidmechanics. The experiments comprise laminar flow (Re = 500) in irregular shaped vessels. The main highlight of the presented GAPINN is the use of PINNs on irregular non‑parameterized geometries. Despite that we showed the usage of this framework for Navier Stokes equations, it should be feasible to adapt this framework for other problems described by PDEs.},
	language = {en},
	number = {1},
	urldate = {2026-02-15},
	journal = {Advanced Modeling and Simulation in Engineering Sciences},
	author = {Oldenburg, Jan and Borowski, Finja and Öner, Alper and Schmitz, Klaus-Peter and Stiehm, Michael},
	month = jun,
	year = {2022},
	pages = {8},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\WFFL6GD2\\Oldenburg et al. - 2022 - Geometry aware physics informed neural network surrogate for solving Navier–Stokes equation (GAPINN).pdf:application/pdf},
}

@article{obrien_imaging_2023,
	title = {Imaging and seismic modelling inside volcanoes using machine learning},
	volume = {13},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-023-27738-6},
	doi = {10.1038/s41598-023-27738-6},
	abstract = {Abstract
            Despite advances in seismology and computing, the ability to image subsurface volcanic environments is poor, limiting our understanding of the overall workings of volcanic systems. This is related to substantive structural heterogeneities which strongly scatters seismic waves obscuring the ballistic arrivals normally used in seismology for wave velocity determination. Here we address this constraint by, using a deep learning approach, a Fourier neural operator (FNO), to model and invert seismic signals in volcanic settings. The FNO is trained using 40,000+ simulations of elastic wave propagation through complex volcano models, and includes the full scattered wavefield. Once trained, the forward network is used to predict elastic wave propagation and is shown to accurately reproduce the seismic wavefield. The FNO is also trained to predict heterogeneous velocity models given a limited set of input seismograms. It is shown to capture details of the complex velocity structure that lie far outside the ability of current methods available in volcano imagery.},
	language = {en},
	number = {1},
	urldate = {2026-02-15},
	journal = {Scientific Reports},
	author = {O’Brien, Gareth Shane and Bean, Christopher J. and Meiland, Hugo and Witte, Philipp},
	month = jan,
	year = {2023},
	pages = {630},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\27Y8KDNY\\O’Brien et al. - 2023 - Imaging and seismic modelling inside volcanoes using machine learning.pdf:application/pdf},
}

@misc{mohapatra_inferring_2025,
	title = {Inferring activity from the flow field around active colloidal particles using deep learning},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2505.10270},
	doi = {10.48550/ARXIV.2505.10270},
	abstract = {Active colloidal particles create flow around them due to non-equilibrium process on their surfaces. In this paper, we infer the activity of such colloidal particles from the flow field created by them via deep learning. We first explain our method for one active particle, inferring the \$2s\$ mode (or the stresslet) and the \$3t\$ mode (or the source dipole) from the flow field data, along with the position and orientation of the particle. We then apply the method to a system of many active particles. We find excellent agreements between the predictions and the true values of activity. Our method presents a principled way to predict arbitrary activity from the flow field created by active particles.},
	language = {en},
	urldate = {2026-02-15},
	publisher = {arXiv},
	author = {Mohapatra, Aditya and Kumar, Aditya and Deb, Mayurakshi and Dhomkar, Siddharth and Singh, Rajesh},
	year = {2025},
	note = {Version Number: 3},
	keywords = {FOS: Physical sciences, Fluid Dynamics (physics.flu-dyn), Soft Condensed Matter (cond-mat.soft)},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\JE65VKCM\\Mohapatra et al. - 2025 - Inferring activity from the flow field around active colloidal particles using deep learning.pdf:application/pdf},
}

@article{sanchez-gonzalez_learning_nodate,
	title = {Learning to {Simulate} {Complex} {Physics} with {Graph} {Networks}},
	abstract = {Here we present a machine learning framework and model implementation that can learn to simulate a wide variety of challenging physical domains, involving ﬂuids, rigid solids, and deformable materials interacting with one another. Our framework—which we term “Graph Network-based Simulators” (GNS)—represents the state of a physical system with particles, expressed as nodes in a graph, and computes dynamics via learned message-passing. Our results show that our model can generalize from single-timestep predictions with thousands of particles during training, to different initial conditions, thousands of timesteps, and at least an order of magnitude more particles at test time. Our model was robust to hyperparameter choices across various evaluation metrics: the main determinants of long-term performance were the number of message-passing steps, and mitigating the accumulation of error by corrupting the training data with noise. Our GNS framework advances the state-of-the-art in learned physical simulation, and holds promise for solving a wide range of complex forward and inverse problems.},
	language = {en},
	author = {Sanchez-Gonzalez, Alvaro and Godwin, Jonathan and Pfaff, Tobias and Ying, Rex and Leskovec, Jure and Battaglia, Peter W},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\BHDL2LZZ\\Sanchez-Gonzalez et al. - Learning to Simulate Complex Physics with Graph Networks.pdf:application/pdf},
}

@article{margenberg_structure_2021,
	title = {Structure preservation for the {Deep} {Neural} {Network} {Multigrid} {Solver}},
	volume = {56},
	issn = {1068-9613, 1068-9613},
	url = {https://hw.oeaw.ac.at?arp=0x003d1ae0},
	doi = {10.1553/etna_vol56s86},
	language = {en},
	urldate = {2026-02-15},
	journal = {ETNA - Electronic Transactions on Numerical Analysis},
	author = {Margenberg, Nils and Lessig, Christian and Richter, Thomas},
	year = {2021},
	pages = {86--101},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\JRUH8BPE\\Margenberg et al. - 2021 - Structure preservation for the Deep Neural Network Multigrid Solver.pdf:application/pdf},
}

@article{kovachki_neural_nodate,
	title = {Neural {Operator}: {Learning} {Maps} {Between} {Function} {Spaces} {With} {Applications} to {PDEs}},
	abstract = {The classical development of neural networks has primarily focused on learning mappings between finite dimensional Euclidean spaces or finite sets. We propose a generalization of neural networks to learn operators, termed neural operators, that map between infinite dimensional function spaces. We formulate the neural operator as a composition of linear integral operators and nonlinear activation functions. We prove a universal approximation theorem for our proposed neural operator, showing that it can approximate any given nonlinear continuous operator. The proposed neural operators are also discretization-invariant, i.e., they share the same model parameters among different discretization of the underlying function spaces. Furthermore, we introduce four classes of efficient parameterization, viz., graph neural operators, multi-pole graph neural operators, lowrank neural operators, and Fourier neural operators. An important application for neural operators is learning surrogate maps for the solution operators of partial differential equations (PDEs). We consider standard PDEs such as the Burgers, Darcy subsurface flow, and the Navier-Stokes equations, and show that the proposed neural operators have superior performance compared to existing machine learning based methodologies, while being several orders of magnitude faster than conventional PDE solvers.},
	language = {en},
	author = {Kovachki, Nikola and Li, Zongyi and Liu, Burigede and Azizzadenesheli, Kamyar and Bhattacharya, Kaushik and Stuart, Andrew},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\BIHFK5EL\\Kovachki et al. - Neural Operator Learning Maps Between Function Spaces With Applications to PDEs.pdf:application/pdf},
}

@article{jin_nsfnets_2021,
	title = {{NSFnets} ({Navier}-{Stokes} flow nets): {Physics}-informed neural networks for the incompressible {Navier}-{Stokes} equations},
	volume = {426},
	issn = {00219991},
	shorttitle = {{NSFnets} ({Navier}-{Stokes} flow nets)},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999120307257},
	doi = {10.1016/j.jcp.2020.109951},
	language = {en},
	urldate = {2026-02-15},
	journal = {Journal of Computational Physics},
	author = {Jin, Xiaowei and Cai, Shengze and Li, Hui and Karniadakis, George Em},
	month = feb,
	year = {2021},
	pages = {109951},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\Z5JVUSYZ\\Jin et al. - 2021 - NSFnets (Navier-Stokes flow nets) Physics-informed neural networks for the incompressible Navier-St.pdf:application/pdf},
}

@article{ladd_numerical_nodate,
	title = {Numerical {Simulations} of {Particulate} {Suspensions} via a {Discretized} {Boltzmann} {Equation} {Part} {I}. {Theoretical} {Foundation}},
	abstract = {A new and very general technique for simulating solid- uid suspensions is described; its most important feature is that the computational cost scales linearly with the number of particles. The method combines Newtonian dynamics of the solid particles with a discretized Boltzmann equation for the uid phase; the many-body hydrodynamic interactions are fully accounted for, both in the creeping- ow regime and at higher Reynolds numbers. Brownian motion of the solid particles arises spontaneously from stochastic uctuations in the uid stress tensor, rather than from random forces or displacements applied directly to the particles. In this paper, the theoretical foundations of the technique are laid out, illustrated by simple analytical and numerical examples; in the companion paper, extensive numerical tests of the method, for stationary ows, time-dependent ows, and nite Reynolds number ows, are reported.},
	language = {en},
	author = {Ladd, Anthony J C},
	year={1994},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\69GMIEUF\\Ladd - Numerical Simulations of Particulate Suspensions via a Discretized Boltzmann Equation Part I. Theore.pdf:application/pdf},
}

@article{thieulot_choice_2022,
	title = {On the choice of finite element for applications in geodynamics},
	volume = {13},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1869-9529},
	url = {https://se.copernicus.org/articles/13/229/2022/},
	doi = {10.5194/se-13-229-2022},
	abstract = {Geodynamical simulations over the past decades have widely been built on quadrilateral and hexahedral ﬁnite elements. For the discretization of the key Stokes equation describing slow, viscous ﬂow, most codes use either the unstable Q1 × P0 element, a stabilized version of the equalorder Q1 × Q1 element, or more recently the stable Taylor–Hood element with continuous (Q2 × Q1) or discontinuous (Q2 × P−1) pressure. However, it is not clear which of these choices is actually the best at accurately simulating “typical” geodynamic situations.},
	language = {en},
	number = {1},
	urldate = {2026-02-15},
	journal = {Solid Earth},
	author = {Thieulot, Cedric and Bangerth, Wolfgang},
	month = jan,
	year = {2022},
	pages = {229--249},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\L94SJ5CU\\Thieulot und Bangerth - 2022 - On the choice of finite element for applications in geodynamics.pdf:application/pdf},
}

@article{kovachki_operator_nodate,
	title = {{OPERATOR} {LEARNING}: {ALGORITHMS} {AND} {ANALYSIS}},
	abstract = {Operator learning refers to the application of ideas from machine learning to approximate (typically nonlinear) operators mapping between Banach spaces of functions. Such operators often arise from physical models expressed in terms of partial differential equations (PDEs). In this context, such approximate operators hold great potential as efficient surrogate models to complement traditional numerical methods in many-query tasks. Being data-driven, they also enable model discovery when a mathematical description in terms of a PDE is not available. This review focuses primarily on neural operators, built on the success of deep neural networks in the approximation of functions defined on finite dimensional Euclidean spaces. Empirically, neural operators have shown success in a variety of applications, but our theoretical understanding remains incomplete. This review article summarizes recent progress and the current state of our theoretical understanding of neural operators, focusing on an approximation theoretic point of view.},
	language = {en},
	author = {Kovachki, Nikola B and Lanthaler, Samuel and Stuart, Andrew M},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\77CBM9QZ\\Kovachki et al. - OPERATOR LEARNING ALGORITHMS AND ANALYSIS.pdf:application/pdf},
}

@article{takamoto_pdebench_nodate,
	title = {{PDEBENCH}: {An} {Extensive} {Benchmark} for {Scientific} {Machine} {Learning}},
	abstract = {Machine learning-based modeling of physical systems has experienced increased interest in recent years. Despite some impressive progress, there is still a lack of benchmarks for Scientific ML that are easy to use but still challenging and representative of a wide range of problems. We introduce PDEBENCH, a benchmark suite of time-dependent simulation tasks based on Partial Differential Equations (PDEs). PDEBENCH comprises both code and data to benchmark the performance of novel machine learning models against both classical numerical simulations and machine learning baselines. Our proposed set of benchmark problems contribute the following unique features: (1) A much wider range of PDEs compared to existing benchmarks, ranging from relatively common examples to more realistic and difficult problems; (2) much larger ready-to-use datasets compared to prior work, comprising multiple simulation runs across a larger number of initial and boundary conditions and PDE parameters; (3) more extensible source codes with user-friendly APIs for data generation and baseline results with popular machine learning models (FNO, U-Net, PINN, Gradient-Based Inverse Method). PDEBENCH allows researchers to extend the benchmark freely for their own purposes using a standardized API and to compare the performance of new models to existing baseline methods. We also propose new evaluation metrics with the aim to provide a more holistic understanding of learning methods in the context of Scientific ML. With those metrics we identify tasks which are challenging for recent ML methods and propose these tasks as future challenges for the community. The code is available at https://github.com/pdebench/PDEBench.},
	language = {en},
	author = {Takamoto, Makoto and Praditia, Timothy and Leiteritz, Raphael and MacKinlay, Dan and Alesiani, Francesco and Pflüger, Dirk and Niepert, Mathias},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\R365KEXU\\Takamoto et al. - PDEBENCH An Extensive Benchmark for Scientific Machine Learning.pdf:application/pdf},
}

@misc{raissi_physics_2017,
	title = {Physics {Informed} {Deep} {Learning} ({Part} {I}): {Data}-driven {Solutions} of {Nonlinear} {Partial} {Differential} {Equations}},
	shorttitle = {Physics {Informed} {Deep} {Learning} ({Part} {I})},
	url = {http://arxiv.org/abs/1711.10561},
	doi = {10.48550/arXiv.1711.10561},
	abstract = {We introduce physics informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given law of physics described by general nonlinear partial diﬀerential equations. In this two part treatise, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial diﬀerential equations. Depending on the nature and arrangement of the available data, we devise two distinct classes of algorithms, namely continuous time and discrete time models. The resulting neural networks form a new class of data-eﬃcient universal function approximators that naturally encode any underlying physical laws as prior information. In this ﬁrst part, we demonstrate how these networks can be used to infer solutions to partial diﬀerential equations, and obtain physics-informed surrogate models that are fully diﬀerentiable with respect to all input coordinates and free parameters.},
	language = {en},
	urldate = {2026-02-15},
	publisher = {arXiv},
	author = {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
	month = nov,
	year = {2017},
	note = {arXiv:1711.10561 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Dynamical Systems, Mathematics - Numerical Analysis, Computer Science - Artificial Intelligence},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\ZAY8ZRXV\\Raissi et al. - 2017 - Physics Informed Deep Learning (Part I) Data-driven Solutions of Nonlinear Partial Differential Equ.pdf:application/pdf},
}

@article{ashwin_physics_2024,
	title = {Physics informed deep learning for flow and force predictions in dense ellipsoidal particle suspensions},
	volume = {439},
	issn = {00325910},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0032591024003267},
	doi = {10.1016/j.powtec.2024.119684},
	abstract = {Solid-fluid multiphase systems are ubiquitous in many chemical, pharmaceutical, and energy based applications. These flows are challenging to study experimentally, thus several numerical simulation techniques have been developed. In this paper we use Particle Resolved Simulations (PRS) combined with Deep Learning (DL) to predict drag forces on each particle in suspensions of ellipsoidal particles for use in lower fidelity Euler-Lagrange and Euler-Euler simulations. Suspensions with solid fraction of 0.1, 0.2 and 0.3 are investigated at Reynolds numbers of 10, 50, 100 and 200. A UNet architecture is used to predict the velocity and pressure fields and a CNN is used to predict the drag forces. It is shown that drag force predictions using the predicted velocity and pressure fields give more accurate results than predictions that only use geometric information.},
	language = {en},
	urldate = {2026-02-15},
	journal = {Powder Technology},
	author = {Ashwin, Neil Raj and Tafti, Danesh and Muralidhar, Nikhil and Cao, Ze},
	month = apr,
	year = {2024},
	pages = {119684},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\ACEWVESH\\Ashwin et al. - 2024 - Physics informed deep learning for flow and force predictions in dense ellipsoidal particle suspensi.pdf:application/pdf},
}

@misc{agarwal_physics-based_2025,
	title = {Physics-based machine learning for mantle convection simulations},
	url = {http://arxiv.org/abs/2505.16041},
	doi = {10.48550/arXiv.2505.16041},
	abstract = {Mantle convection simulations are an essential tool for understanding how rocky planets evolve. However, the poorly known input parameters to these simulations, the non-linear dependence of transport properties on pressure and temperature, and the long integration times in excess of several billion years all pose a computational challenge for numerical solvers. We propose a physics-based machine learning approach that predicts creeping flow velocities as a function of temperature while conserving mass, thereby bypassing the numerical solution of the Stokes problem. A finite-volume solver then uses the predicted velocities to advect and diffuse the temperature field to the next time-step, enabling autoregressive rollout at inference. For training, our model requires temperature-velocity snapshots from a handful of simulations (94). We consider mantle convection in a two-dimensional rectangular box with basal and internal heating, pressure- and temperature-dependent viscosity. Overall, our model is up to 89 times faster than the numerical solver. We also show the importance of different components in our convolutional neural network architecture such as mass conservation, learned paddings on the boundaries, and loss scaling for the overall rollout performance. Finally, we test our approach on unseen scenarios to demonstrate some of its strengths and weaknesses.},
	language = {en},
	urldate = {2026-02-15},
	publisher = {arXiv},
	author = {Agarwal, Siddhant and Bekar, Ali Can and Hüttig, Christian and Greenberg, David S. and Tosi, Nicola},
	month = may,
	year = {2025},
	note = {arXiv:2505.16041 [astro-ph]},
	keywords = {Computer Science - Machine Learning, Astrophysics - Earth and Planetary Astrophysics},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\RLQHU98W\\Agarwal et al. - 2025 - Physics-based machine learning for mantle convection simulations.pdf:application/pdf},
}

@article{zhu_physics-constrained_2019,
	title = {Physics-{Constrained} {Deep} {Learning} for {High}-dimensional {Surrogate} {Modeling} and {Uncertainty} {Quantification} without {Labeled} {Data}},
	volume = {394},
	issn = {00219991},
	url = {http://arxiv.org/abs/1901.06314},
	doi = {10.1016/j.jcp.2019.05.024},
	abstract = {Surrogate modeling and uncertainty quantification tasks for PDE systems are most often considered as supervised learning problems where input and output data pairs are used for training. The construction of such emulators is by definition a small data problem which poses challenges to deep learning approaches that have been developed to operate in the big data regime. Even in cases where such models have been shown to have good predictive capability in high dimensions, they fail to address constraints in the data implied by the PDE model. This paper provides a methodology that incorporates the governing equations of the physical model in the loss/likelihood functions. The resulting physics-constrained, deep learning models are trained without any labeled data (e.g. employing only input data) and provide comparable predictive responses with data-driven models while obeying the constraints of the problem at hand. This work employs a convolutional encoder-decoder neural network approach as well as a conditional flow-based generative model for the solution of PDEs, surrogate model construction, and uncertainty quantification tasks. The methodology is posed as a minimization problem of the reverse Kullback-Leibler (KL) divergence between the model predictive density and the reference conditional density, where the later is defined as the Boltzmann-Gibbs distribution at a given inverse temperature with the underlying potential relating to the PDE system of interest. The generalization capability of these models to out-of-distribution input is considered. Quantification and interpretation of the predictive uncertainty is provided for a number of problems.},
	language = {en},
	urldate = {2026-02-15},
	journal = {Journal of Computational Physics},
	author = {Zhu, Yinhao and Zabaras, Nicholas and Koutsourelakis, Phaedon-Stelios and Perdikaris, Paris},
	month = oct,
	year = {2019},
	note = {arXiv:1901.06314 [physics]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
	pages = {56--81},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\R72Z3QMF\\Zhu et al. - 2019 - Physics-Constrained Deep Learning for High-dimensional Surrogate Modeling and Uncertainty Quantifica.pdf:application/pdf},
}

@article{li_physics-informed_2024,
	title = {Physics-{Informed} {Neural} {Operator} for {Learning} {Partial} {Differential} {Equations}},
	volume = {1},
	copyright = {https://www.acm.org/publications/policies/copyright\_policy\#Background},
	issn = {2831-3194},
	url = {https://dl.acm.org/doi/10.1145/3648506},
	doi = {10.1145/3648506},
	abstract = {In this article, we propose physics-informed neural operators (PINO) that combine training data and physics constraints to learn the solution operator of a given family of parametric Partial Differential Equations (PDE). PINO is the first hybrid approach incorporating data and PDE constraints at different resolutions to learn the operator. Specifically, in PINO, we combine coarse-resolution training data with PDE constraints imposed at a higher resolution. The resulting PINO model can accurately approximate the ground-truth solution operator for many popular PDE families and shows no degradation in accuracy even under zero-shot super-resolution, that is, being able to predict beyond the resolution of training data. PINO uses the Fourier neural operator (FNO) framework that is guaranteed to be a universal approximator for any continuous operator and discretization convergent in the limit of mesh refinement. By adding PDE constraints to FNO at a higher resolution, we obtain a high-fidelity reconstruction of the ground-truth operator. Moreover, PINO succeeds in settings where no training data is available and only PDE constraints are imposed, while previous approaches, such as the Physics-Informed Neural Network (PINN), fail due to optimization challenges, for example, in multi-scale dynamic systems such as Kolmogorov flows.
          , 
            Highlights
            
              PROBLEM STATEMENT
            
            Machine learning methods have recently shown promise in solving partial differential equations (PDEs) raised in science and engineering. They can be classified into two broad categories: approximating the solution function  and learning the solution operator. The Physics-Informed Neural Network (PINN) is an example of the former while the Fourier neural operator (FNO) is an example of the latter. Both these approaches have shortcomings. The optimization in PINN is challenging and prone to failure, especially on multi-scale dynamic systems. FNO does not suffer from this optimization issue since it carries out supervised learning on a given dataset, but obtaining such data may be too expensive or infeasible. In this paper, we consider a new learning paradigm, aiming to overcome the optimization challenge in PINN and relieve the data requirement in FNO.
            
              METHODS
            
            In this paper, we propose physics-informed neural operators (PINO) that combine training data and physics constraints to learn the solution operator of a given family of parametric PDEs.
            In the operator-learning phase, PINO learns the solution operator over multiple instances of the parametric PDE family using training data and physics constraints. In the instance-wise fine-tuning phase, PINO optimizes the pre-trained operator ansatz for the querying instance of the PDE using the physics constraints only.
            Specifically, we combine coarse-resolution training data with PDE constraints imposed at a higher resolution. By adding PDE constraints to FNO at a higher resolution, we obtain a high-fidelity reconstruction of the ground-truth operator.
            
              RESULTS
            
            The resulting PINO model can accurately approximate the ground-truth solution operator for many popular PDE families and shows no degradation in accuracy even under zero-shot super-resolution, i.e., being able to predict beyond the resolution of training data.
            Experiments show PINO outperforms previous ML methods on many popular PDE families while retaining the extraordinary speed-up of FNO compared to solvers. With the equation constraints, PINO requires few to no data to learn the Burgers, Darcy, and Navier-Stokes equation. In particular, PINO accurately solves long temporal transient flows and  Kolmogorov flows where other baseline methods fail to converge.
            
              SIGNIFICANCE
            
            PINO uses the neural operator framework that is guaranteed to be a universal approximator for any continuous operator and discretization convergent in the limit of mesh refinement. Moreover, PINO succeeds in settings where no training data is available and only PDE constraints are imposed. These advantages could lead to applications such as weather forecast, airfoil designs, and turbulence control.},
	language = {en},
	number = {3},
	urldate = {2026-02-15},
	journal = {ACM / IMS Journal of Data Science},
	author = {Li, Zongyi and Zheng, Hongkai and Kovachki, Nikola and Jin, David and Chen, Haoxuan and Liu, Burigede and Azizzadenesheli, Kamyar and Anandkumar, Anima},
	month = sep,
	year = {2024},
	pages = {1--27},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\XZ8B8E34\\Li et al. - 2024 - Physics-Informed Neural Operator for Learning Partial Differential Equations.pdf:application/pdf},
}

@article{richter-powell_neural_nodate,
	title = {Neural {Conservation} {Laws}: {A} {Divergence}-{Free} {Perspective}},
	abstract = {We investigate the parameterization of deep neural networks that by design satisfy the continuity equation, a fundamental conservation law. This is enabled by the observation that any solution of the continuity equation can be represented as a divergence-free vector field. We hence propose building divergence-free neural networks through the concept of differential forms, and with the aid of automatic differentiation, realize two practical constructions. As a result, we can parameterize pairs of densities and vector fields that always exactly satisfy the continuity equation, foregoing the need for extra penalty methods or expensive numerical simulation. Furthermore, we prove these models are universal and so can be used to represent any divergence-free vector field. Finally, we experimentally validate our approaches by computing neural network-based solutions to fluid equations, solving for the Hodge decomposition, and learning dynamical optimal transport maps.},
	language = {en},
	author = {Richter-Powell, Jack and Lipman, Yaron and Chen, Ricky T Q},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\2EJUHHVU\\Richter-Powell et al. - Neural Conservation Laws A Divergence-Free Perspective.pdf:application/pdf},
}

@article{patocka_settling_2020,
	title = {Settling of inertial particles in turbulent {Rayleigh}-{Benard} convection},
	volume = {5},
	issn = {2469-990X},
	url = {http://arxiv.org/abs/2005.05448},
	doi = {10.1103/PhysRevFluids.5.114304},
	abstract = {The settling behaviour of small inertial particles in turbulent convection is a fundamental problem across several disciplines, from geophysics to metallurgy. In a geophysical context, the settling of dense crystals controls the mode of solidification of magma chambers and planetary-scale magma oceans, while rising of light bubbles of volatiles drives volcanic outgassing and the formation of primordial atmospheres. Motivated by these geophysical systems, we perform a systematic numerical study on the settling rate of particles in a rectangular two-dimensional Rayleigh-Benard system with Rayleigh number up to 10{\textasciicircum}12 and Prandtl number from 10 to 50. Under the idealized condition of spherically-shaped particles with small Reynolds number, two limiting behaviours exist for the settling velocity. On the one hand, Stokes' law applies to particles with small but finite response time, leading to a constant settling rate. On the other hand, particles with a vanishing response time are expected to settle at an exponential rate. Based on our simulations, we present a new physical model that bridges the gap between the above limiting behaviours by describing the sedimentation of inertial particles as a random process with two key components: i) the transport of particles from vigorously convecting regions into sluggish, low-velocity "piles" that naturally develop at the horizontal boundaries of the system, and ii) the probability that particles escape such low-velocity regions without settling at their base. In addition, we identify four distinct settling regimes and analyze the horizontal distribution of sedimented particles. For two of these regimes settling is particularly slow and the distribution is strongly non-uniform, with dense particles being deposited preferentially below major clusters of upwellings.},
	language = {en},
	number = {11},
	urldate = {2026-02-15},
	journal = {Physical Review Fluids},
	author = {Patocka, Vojtech and Calzavarini, Enrico and Tosi, Nicola},
	month = nov,
	year = {2020},
	note = {arXiv:2005.05448 [physics]},
	keywords = {Condensed Matter - Soft Condensed Matter, Physics - Fluid Dynamics, Physics - Geophysics},
	pages = {114304},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\NYM3DAKS\\Patocka et al. - 2020 - Settling of inertial particles in turbulent Rayleigh-Benard convection.pdf:application/pdf},
}

@article{sun_surrogate_2020,
	title = {Surrogate {Modeling} for {Fluid} {Flows} {Based} on {Physics}-{Constrained} {Deep} {Learning} {Without} {Simulation} {Data}},
	volume = {361},
	issn = {00457825},
	url = {http://arxiv.org/abs/1906.02382},
	doi = {10.1016/j.cma.2019.112732},
	abstract = {Numerical simulations on fluid dynamics problems primarily rely on spatially or/and temporally discretization of the governing equation into the finite-dimensional algebraic system solved by computers. Due to complicated nature of the physics and geometry, such process can be computational prohibitive for most real-time applications and many-query analyses. Therefore, developing a cost-effective surrogate model is of great practical significance. Deep learning (DL) has shown new promises for surrogate modeling due to its capability of handling strong nonlinearity and high dimensionality. However, the off-the-shelf DL architectures fail to operate when the data becomes sparse. Unfortunately, data is often insufficient in most parametric fluid dynamics problems since each data point in the parameter space requires an expensive numerical simulation based on the first principle, e.g., Naiver--Stokes equations. In this paper, we provide a physics-constrained DL approach for surrogate modeling of fluid flows without relying on any simulation data. Specifically, a structured deep neural network (DNN) architecture is devised to enforce the initial and boundary conditions, and the governing partial differential equations are incorporated into the loss of the DNN to drive the training. Numerical experiments are conducted on a number of internal flows relevant to hemodynamics applications, and the forward propagation of uncertainties in fluid properties and domain geometry is studied as well. The results show excellent agreement on the flow field and forward-propagated uncertainties between the DL surrogate approximations and the first-principle numerical simulations.},
	language = {en},
	urldate = {2026-02-15},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Sun, Luning and Gao, Han and Pan, Shaowu and Wang, Jian-Xun},
	month = apr,
	year = {2020},
	note = {arXiv:1906.02382 [physics]},
	keywords = {Physics - Computational Physics},
	pages = {112732},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\D89Q86IW\\Sun et al. - 2020 - Surrogate Modeling for Fluid Flows Based on Physics-Constrained Deep Learning Without Simulation Dat.pdf:application/pdf},
}

@article{le_surrogate_2021,
	title = {Surrogate modeling of fluid dynamics with a multigrid inspired neural network architecture},
	volume = {6},
	issn = {26668270},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2666827021000888},
	doi = {10.1016/j.mlwa.2021.100176},
	abstract = {Algebraic or geometric multigrid methods are commonly used in numerical solvers as they are a multiresolution method able to handle problems with multiple scales. In this work, we propose a modification to the commonly-used U-Net neural network architecture that is inspired by the principles of multigrid methods, referred to here as U-Net-MG. We then demonstrate that this proposed U-Net-MG architecture can successfully reduce the test prediction errors relative to the conventional U-Net architecture when modeling a set of fluid dynamic problems. In total, we demonstrate an improvement in the prediction of velocity and pressure fields for the canonical fluid dynamics cases of flow past a stationary cylinder, flow past 2 cylinders in out-of-phase motion, and flow past an oscillating airfoil in both the propulsion and energy harvesting modes. In general, while both the U-Net and U-Net-MG models can model the systems well with test RMSEs of less than 1\%, the use of the U-Net-MG architecture can further reduce RMSEs by between 20\% and 70\%.},
	language = {en},
	urldate = {2026-02-15},
	journal = {Machine Learning with Applications},
	author = {Le, Quang Tuyen and Ooi, Chinchun},
	month = dec,
	year = {2021},
	pages = {100176},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\28RWQMXR\\Le und Ooi - 2021 - Surrogate modeling of fluid dynamics with a multigrid inspired neural network architecture.pdf:application/pdf},
}

@misc{qin_toward_2024,
	title = {Toward a {Better} {Understanding} of {Fourier} {Neural} {Operators} from a {Spectral} {Perspective}},
	url = {http://arxiv.org/abs/2404.07200},
	doi = {10.48550/arXiv.2404.07200},
	abstract = {In solving partial differential equations (PDEs), Fourier Neural Operators (FNOs) have exhibited notable effectiveness. However, FNO is observed to be ineffective with large Fourier kernels that parameterize more frequencies. Current solutions rely on setting small kernels, restricting FNO’s ability to capture complex PDE data in real-world applications. This paper offers empirical insights into FNO’s difficulty with large kernels through spectral analysis: FNO exhibits a unique Fourier parameterization bias, excelling at learning dominant frequencies in target data while struggling with non-dominant frequencies. To mitigate such a bias, we propose SpecB-FNO to enhance the capture of non-dominant frequencies by adopting additional residual modules to learn from the previous ones’ prediction residuals iteratively. By effectively utilizing large Fourier kernels, SpecB-FNO achieves better prediction accuracy on diverse PDE applications, with an average improvement of 50\%.},
	language = {en},
	urldate = {2026-02-15},
	publisher = {arXiv},
	author = {Qin, Shaoxiang and Lyu, Fuyuan and Peng, Wenhui and Geng, Dingyang and Wang, Ju and Tang, Xing and Leroyer, Sylvie and Gao, Naiping and Liu, Xue and Wang, Liangzhu Leon},
	month = oct,
	year = {2024},
	note = {arXiv:2404.07200 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\RMC8F5A4\\Qin et al. - 2024 - Toward a Better Understanding of Fourier Neural Operators from a Spectral Perspective.pdf:application/pdf},
}

@misc{gupta_towards_2022,
	title = {Towards {Multi}-spatiotemporal-scale {Generalized} {PDE} {Modeling}},
	url = {http://arxiv.org/abs/2209.15616},
	doi = {10.48550/arXiv.2209.15616},
	abstract = {Partial differential equations (PDEs) are central to describing complex physical system simulations. Their expensive solution techniques have led to an increased interest in deep neural network based surrogates. However, the practical utility of training such surrogates is contingent on their ability to model complex multi-scale spatio-temporal phenomena. Various neural network architectures have been proposed to target such phenomena, most notably Fourier Neural Operators (FNOs), which give a natural handle over local \& global spatial information via parameterization of different Fourier modes, and U-Nets which treat local and global information via downsampling and upsampling paths. However, generalizing across different equation parameters or time-scales still remains a challenge. In this work, we make a comprehensive comparison between various FNO, ResNet, and U-Net like approaches to fluid mechanics problems in both vorticity-stream and velocity function form. For U-Nets, we transfer recent architectural improvements from computer vision, most notably from object segmentation and generative modeling. We further analyze the design considerations for using FNO layers to improve performance of U-Net architectures without major degradation of computational cost. Finally, we show promising results on generalization to different PDE parameters and time-scales with a single surrogate model. Source code for our PyTorch benchmark framework is available at https://github.com/microsoft/pdearena.},
	language = {en},
	urldate = {2026-02-15},
	publisher = {arXiv},
	author = {Gupta, Jayesh K. and Brandstetter, Johannes},
	month = nov,
	year = {2022},
	note = {arXiv:2209.15616 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\IM76PLVT\\Gupta und Brandstetter - 2022 - Towards Multi-spatiotemporal-scale Generalized PDE Modeling.pdf:application/pdf},
}

@article{wen_u-fnoenhanced_2022,
	title = {U-{FNO}—{An} enhanced {Fourier} neural operator-based deep-learning model for multiphase flow},
	volume = {163},
	issn = {03091708},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0309170822000562},
	doi = {10.1016/j.advwatres.2022.104180},
	abstract = {Numerical simulation of multiphase flow in porous media is essential for many geoscience applications. Machine learning models trained with numerical simulation data can provide a faster alternative to traditional simulators. Here we present U-FNO, a novel neural network architecture for solving multiphase flow problems with superior accuracy, speed, and data efficiency. U-FNO is designed based on the newly proposed Fourier neural operator (FNO), which has shown excellent performance in single-phase flows. We extend the FNObased architecture to a highly complex CO2-water multiphase problem with wide ranges of permeability and porosity heterogeneity, anisotropy, reservoir conditions, injection configurations, flow rates, and multiphase flow properties. The U-FNO architecture is more accurate in gas saturation and pressure buildup predictions than the original FNO and a state-of-the-art convolutional neural network (CNN) benchmark. Meanwhile, it has superior data utilization efficiency, requiring only a third of the training data to achieve the equivalent accuracy as CNN. U-FNO provides superior performance in highly heterogeneous geological formations and critically important applications such as gas saturation and pressure buildup ‘‘fronts’’ determination. The trained model can serve as a general-purpose alternative to routine numerical simulations of 2D-radial CO2 injection problems with significant speed-ups than traditional simulators.},
	language = {en},
	urldate = {2026-02-15},
	journal = {Advances in Water Resources},
	author = {Wen, Gege and Li, Zongyi and Azizzadenesheli, Kamyar and Anandkumar, Anima and Benson, Sally M.},
	month = may,
	year = {2022},
	pages = {104180},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\P9SWMCJ2\\Wen et al. - 2022 - U-FNO—An enhanced Fourier neural operator-based deep-learning model for multiphase flow.pdf:application/pdf},
}

@article{chen_u-net_nodate,
	title = {U-net architectures for fast prediction in fluid mechanics},
	abstract = {Machine learning is a popular tool that is being applied to many domains, from computer vision to natural language processing. It is not long ago that its use was extended to physics, but its capabilities remain to be accurately contoured. In this paper, we are interested in the prediction of 2D velocity and pressure ﬁelds around arbitrary shapes in laminar ﬂows using supervised neural networks. To this end, a dataset composed of random shapes is built using B´ezier curves, each shape being labeled with its pressure and velocity ﬁelds by solving Navier-Stokes equations using a CFD solver. Then, several U-net architectures are trained on the latter dataset, and their predictive eﬃciency is assessed on unseen shapes, using ad hoc error functions.},
	language = {en},
	author = {Chen, Junfeng and Viquerat, Jonathan and Hachem, Elie},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\WM2CL78Q\\Chen et al. - U-net architectures for fast prediction in fluid mechanics.pdf:application/pdf},
}

@misc{ronneberger_u-net_2015,
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	shorttitle = {U-{Net}},
	url = {http://arxiv.org/abs/1505.04597},
	doi = {10.48550/arXiv.1505.04597},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more eﬃciently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caﬀe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
	language = {en},
	urldate = {2026-02-15},
	publisher = {arXiv},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	month = may,
	year = {2015},
	note = {arXiv:1505.04597 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\G444I7CP\\Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image Segmentation.pdf:application/pdf},
}

@article{le_u-net-based_2022,
	title = {U-{Net}-{Based} {Surrogate} {Model} for {Evaluation} of {Microfluidic} {Channels}},
	volume = {19},
	issn = {0219-8762, 1793-6969},
	url = {https://www.worldscientific.com/doi/10.1142/S0219876221410188},
	doi = {10.1142/S0219876221410188},
	abstract = {Microfluidics have shown great promise in multiple applications, especially in biomedical diagnostics and separations. While the flow properties of these microfluidic devices can be solved by numerical methods such as computational fluid dynamics (CFD), the process of mesh generation and setting up a numerical solver requires some domain familiarity, while more intuitive commercial programs such as Fluent and StarCCM can be expensive. Hence, in this work, we demonstrated the use of a U-Net convolutional neural network as a surrogate model for predicting the velocity and pressure fields that would result for a particular set of microfluidic filter designs. The surrogate model is fast, easy to set-up and can be used to predict and assess the flow velocity and pressure fields across the domain for new designs of interest via the input of a geometry-encoding matrix. In addition, we demonstrate that the same methodology can also be used to train a network to predict pressure based on velocity data, and propose that this can be an alternative to numerical algorithms for calculating pressure based on velocity measurements from particle-image velocimetry measurements. Critically, in both applications, we demonstrate prediction test errors of less than 1\%, suggesting that this is indeed a viable method.},
	language = {en},
	number = {07},
	urldate = {2026-02-15},
	journal = {International Journal of Computational Methods},
	author = {Le, Tuyen Quang and Chiu, Pao-Hsiung and Ooi, Chinchun},
	month = sep,
	year = {2022},
	pages = {2141018},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\B5H3GTVG\\Le et al. - 2022 - U-Net-Based Surrogate Model for Evaluation of Microfluidic Channels.pdf:application/pdf},
}

@article{martin_fluid-dynamical_1989,
	title = {A {Fluid}-{Dynamical} {Study} of {Crystal} {Settling} in {Convecting} {Magmas}},
	volume = {30},
	issn = {0022-3530, 1460-2415},
	url = {https://academic.oup.com/petrology/article-lookup/doi/10.1093/petrology/30.6.1471},
	doi = {10.1093/petrology/30.6.1471},
	abstract = {Thermal convection in magma chambers is believed to be almost always highly time-dependent, or 'turbulent', and predicted convective velocities are commonly orders of magnitude larger than settling velocities for typical crystals calculated from Stokes' Law. To understand crystal settling in magma chambers we have therefore undertaken a theoretical and experimental study of particle settling in a turbulently convecting fluid. The regime of interest is where the ratio, S, of the Stokes' Law settling velocity, v,, to the root mean square vertical component of convective velocity, W, at mid-depth in the fluid is less than unity. Although v, {\textless} W, settling is still possible because convective velocities are height-dependent and must decrease to zero at the boundaries of the fluid. Particles immediately adjacent to the bottom boundary settle out with their full Stokes' settling velocities. At the same time, convection is vigorous enough to ensure that the distribution of particles in the fluid is uniform. It follows that the number of particles in suspension decays with time according to an exponential law, and the decay constant is simply the ratio of v, to h, the depth of the fluid. Experiments confirm this relationship, at least for low particle concentrations, provided S {\textless} 0-5 and there is no re-entrainment of particles from the floor of the tank. We apply this relationship to crystals in magma chambers and so calculate residence times for typical crystals. We find that for basaltic magmas the predicted residence times are small compared with the many thousands of years that a chamber takes to solidify if cooling is dominated by conduction through the country rock. We therefore conclude that crystal settling may be an efficient differentiation mechanism. Significant magmatic evolution may, however, take place on time-scales that are competitive with these residence times.},
	language = {en},
	number = {6},
	urldate = {2026-02-15},
	journal = {Journal of Petrology},
	author = {Martin, D. and Nokes, R.},
	month = dec,
	year = {1989},
	pages = {1471--1500},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\EJCHKFMJ\\Martin und Nokes - 1989 - A Fluid-Dynamical Study of Crystal Settling in Convecting Magmas.pdf:application/pdf},
}

@article{weinstein_evolution_1988,
	title = {Evolution of crystal-settling in magma-chamber convection},
	volume = {87},
	issn = {0012-821X},
	url = {https://www.sciencedirect.com/science/article/pii/0012821X88900787},
	doi = {https://doi.org/10.1016/0012-821X(88)90078-7},
	abstract = {The motion of negatively buoyant particles embedded within kinematically prescribed convective velocity fields is used to study the evolution of crystal settling in magma chambers. We consider the effects of Stokesian settling velocity, crystal growth, aspect ratio of the convective domain and the site of crystal nucleation on mixing and transport of heavy crystals in this system. The percentage of particles retained in a convecting fluid is very sensitive to the site of nucleation. Particles nucleating along the cold roof or within the wall boundary layers are generally not retained. As a consequence, crystal settling can occur even in rapidly convecting magma chambers. Equilibrium crystal densities are reached relatively quickly, within one overturn, and the distribution of particles deposited on the bottom of the chamber is always asymmetric. This feature may facilitate the formation of primary sedimentary structures in plutons. Laboratory experiments using small, negatively buoyant spheres in a highly viscous fluid with axisymmetric thermal convection confirm the basic predictions of this model.},
	number = {1},
	journal = {Earth and Planetary Science Letters},
	author = {Weinstein, Stuart A. and Yuen, David A. and Olson, Peter L.},
	year = {1988},
	pages = {237--248},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\ZTBZ7DHW\\Weinstein et al. - 1988 - Evolution of crystal-settling in magma-chamber convection.pdf:application/pdf},
}

@article{uhlmann_sedimentation_2014,
	title = {Sedimentation of a dilute suspension of rigid spheres at intermediate {Galileo} numbers: the effect of clustering upon the particle motion},
	volume = {752},
	issn = {0022-1120, 1469-7645},
	shorttitle = {Sedimentation of a dilute suspension of rigid spheres at intermediate {Galileo} numbers},
	url = {http://arxiv.org/abs/1406.1667},
	doi = {10.1017/jfm.2014.330},
	abstract = {Direct numerical simulation of the gravity-induced settling of ﬁnite-size particles in triplyperiodic domains has been performed under dilute conditions. For a single solid-to-ﬂuid density ratio of 1.5 we have considered two values of the Galileo number corresponding to steady vertical motion (Ga = 121) and to steady oblique motion (Ga = 178) in the case of one isolated sphere. For the multi-particle system we observe strong particle clustering only in the latter case. The geometry and time scales related to clustering are determined from Voronoı¨ tesselation and particle-conditioned averaging. As a consequence of clustering, the average particle settling velocity is increased by 12\% as compared to the value of an isolated sphere; such a collective eﬀect is not observed in the non-clustering case. By deﬁning a local (instantaneous) ﬂuid velocity average in the vicinity of the ﬁnite-size particles it is shown that the observed enhancement of the settling velocity is due to the fact that the downward ﬂuid motion (with respect to the global average) which is induced in the cluster regions is preferentially sampled by the particles. It is further observed that the variance of the particle velocity is strongly enhanced in the clustering case. With the aid of a decomposition of the particle velocity it is shown that this increase is due to enhanced ﬂuid velocity ﬂuctuations (due to clustering) in the vicinity of the particles. Finally, we discuss a possible explanation for the observation of a critical Galileo number marking the onset of clustering under dilute conditions.},
	language = {en},
	urldate = {2026-02-15},
	journal = {Journal of Fluid Mechanics},
	author = {Uhlmann, Markus and Doychev, Todor},
	month = aug,
	year = {2014},
	note = {arXiv:1406.1667 [physics]},
	keywords = {Physics - Fluid Dynamics},
	pages = {310--348},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\YK9M9DR9\\Uhlmann und Doychev - 2014 - Sedimentation of a dilute suspension of rigid spheres at intermediate Galileo numbers the effect of.pdf:application/pdf},
}

@article{penlou_experimental_2023,
	title = {Experimental {Measurement} of {Enhanced} and {Hindered} {Particle} {Settling} in {Turbulent} {Gas}‐{Particle} {Suspensions}, and {Geophysical} {Implications}},
	volume = {128},
	issn = {2169-9313, 2169-9356},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022JB025809},
	doi = {10.1029/2022JB025809},
	abstract = {The dynamics of geophysical dilute turbulent gas-particles mixtures depends to a large extent on particle concentration, which in turn depends predominantly on the particle settling velocity. We experimentally investigate air-particle mixtures contained in a vertical pipe in which the velocity of an ascending air flux matches the settling velocity of glass particles. To obtain local particle concentrations in these mixtures, we use acoustic probing and air pressure measurements and show that these independent techniques yield similar results for a range of particle sizes and particle concentrations. Moreover, we find that in suspensions of small particles (78 μm) the settling velocity increases with the local particle concentration due to the formation of particle clusters. These clusters settle with a velocity that is four times faster than the terminal settling velocity of single particles, and they double settling speeds of the suspensions. In contrast, in suspensions of larger particles (467 μm) the settling velocity decreases with increasing particle concentration. Although particle clusters are still present in this case, the settling velocity is decreased by 30\%, which is captured by a hindered settling model. These results suggest an interplay between hindered settling and cluster-induced enhanced settling, which in our experiments occur respectively at Stokes number O(100) and O(1). We discuss implications for volcanic plumes and pyroclastic currents. Our study suggests that clustering and related enhanced or hindered particle settling velocities should be considered in models of volcanic phenomena and that drag law corrections are needed for reliable predictions and hazard assessment.},
	language = {en},
	number = {3},
	urldate = {2026-02-15},
	journal = {Journal of Geophysical Research: Solid Earth},
	author = {Penlou, Baptiste and Roche, Olivier and Manga, Michael and Van Den Wildenberg, Siet},
	month = mar,
	year = {2023},
	pages = {e2022JB025809},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\BSNFB9CC\\Penlou et al. - 2023 - Experimental Measurement of Enhanced and Hindered Particle Settling in Turbulent Gas‐Particle Suspen.pdf:application/pdf},
}

@article{nissanka_dynamics_2023,
	title = {Dynamics of {Mass} {Polar} {Spheroids} {During} {Sedimentation}},
	volume = {956},
	issn = {0022-1120, 1469-7645},
	url = {http://arxiv.org/abs/2206.09505},
	doi = {10.1017/jfm.2023.32},
	abstract = {The dynamics of sedimenting particles under gravity are surprisingly complex due to the presence of effective long-ranged forces. When the particles are polar with a well-defined symmetry axis and non-uniform density, recent theoretical predictions suggest that prolate objects will repel and oblate ones will weakly attract. We tested these predictions using mass polar proalte spheroids, which are composed of 2 mm spheres glued together. We probed different aspect rations (\$κ\$) and center of mass offsets (\$χ\$) by combining spheres of different densities. Experiments were done in both quasi-two-dimensional (2D) and three=dimensional (3D) chambers. By optically tracking the motion of single particles, we found that the dynamics were well-described by a reduced mobility matrix model that could be solved analytically. Pairs of particles exhibited an effective repulsion, and their separation roughly scaled as {\textasciitilde}\$(κ-1)/χ{\textasciicircum}\{0.39\}\$, i.e. particles that were more prolate or had smaller mass asymmetry had stronger repulsion effects. In 3D, particles with \$χ{\textgreater}0\$ were distributed more uniformly than \$χ=0\$ particles, and the degree of uniformity increased with \$κ\$, indicating that the effective 2-body repulsion manifests for a large number of particles.},
	language = {en},
	urldate = {2026-02-15},
	journal = {Journal of Fluid Mechanics},
	author = {Nissanka, Kavinda J. and Ma, Xiaolei and Burton, Justin C.},
	month = feb,
	year = {2023},
	note = {arXiv:2206.09505 [cond-mat]},
	keywords = {Condensed Matter - Soft Condensed Matter},
	pages = {A28},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\HUUWPBSU\\Nissanka et al. - 2023 - Dynamics of Mass Polar Spheroids During Sedimentation.pdf:application/pdf},
}

@article{raissi_physics-informed_2019,
	title = {Physics-informed neural networks: {A} deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
	volume = {378},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999118307125},
	doi = {https://doi.org/10.1016/j.jcp.2018.10.045},
	abstract = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.},
	journal = {Journal of Computational Physics},
	author = {Raissi, M. and Perdikaris, P. and Karniadakis, G. E.},
	year = {2019},
	keywords = {Data-driven scientific computing, Machine learning, Nonlinear dynamics, Predictive modeling, Runge–Kutta methods},
	pages = {686--707},
}


@Article{Li_IBM-LBM-DEM_2022,
AUTHOR = {Li, Xiaohui and Liu, Guodong and Zhao, Junnan and Yin, Xiaolong and Lu, Huilin},
TITLE = {IBM-LBM-DEM Study of Two-Particle Sedimentation: Drafting-Kissing-Tumbling and Effects of Particle Reynolds Number and Initial Positions of Particles},
JOURNAL = {Energies},
VOLUME = {15},
YEAR = {2022},
NUMBER = {9},
ARTICLE-NUMBER = {3297},
URL = {https://www.mdpi.com/1996-1073/15/9/3297},
ISSN = {1996-1073},
ABSTRACT = {Particle sedimentation is a fundamental process encountered in various industrial applications. In this study, we used immersed boundary lattice Boltzmann method and discrete element method (IBM-LBM-DEM) to investigate two-particle sedimentation. A lattice Boltzmann method was used to simulate fluid flow, a discrete element method was used to simulate particle dynamics, and an immersed boundary method was used to handle particle–fluid interactions. Via the IBM-LBM-DEM, the particles collision process in fluid or between rigid walls can be calculated to capture the information of particles and the flow field more efficiently and accurately. The numerical method was verified by simulating settling of a single three-dimensional particle. Then, the effects of Reynolds number (Re), initial distance, and initial angle of particles on two-particle sedimentation were characterized. A specific focus was to reproduce, analyze, and define the well-known phenomenon of drafting-kissing-tumbling (DKT) interaction between two particles. Further kinematic analysis to define DKT is meaningful for two-particle sedimentation studies at different particle locations. Whether a pair of particles has experienced DKT can be viewed from time plots of the distance between the particles (for kissing), the second-order derivative of distance to time (for drafting), and angular velocities of particles (for tumbling). Simulation results show that DKT’s signatures, including attraction, (near) contact, rotation, and in the end, separation, is only completely demonstrated when particles have nearly vertically aligned initial positions. Hence, not all initial positions of particles and Reynolds numbers lead to DKT and not all particle–particle hydrodynamic interactions are DKT. Whether particle–particle interaction is attractive or repulsive depends on the relative positions of particles and Re. Collision occurs when Re is high and the initial angle is small (<20°), almost independent of the initial distance.},
DOI = {10.3390/en15093297}
}


@article{leonardi_coupled_2014,
	title = {Coupled {DEM}-{LBM} method for the free-surface simulation of heterogeneous suspensions},
	volume = {1},
	rights = {http://www.springer.com/tdm},
	issn = {2196-4378, 2196-4386},
	url = {http://link.springer.com/10.1007/s40571-014-0001-z},
	doi = {10.1007/s40571-014-0001-z},
	abstract = {The complexity of the interactions between the constituent granular and liquid phases of a suspension requires an adequate treatment of the constituents themselves. A promising way for numerical simulations of such systems is given by hybrid computational frameworks. This is naturally done, when the Lagrangian description of particle dynamics of the granular phase ﬁnds a correspondence in the ﬂuid description. In this work we employ extensions of the Lattice-Boltzmann Method for non-Newtonian rheology, free surfaces, and moving boundaries. The models allows for a full coupling of the phases, but in a simpliﬁed way. An experimental validation is given by an example of gravity driven ﬂow of a particle suspension.},
	pages = {3--13},
	number = {1},
	journaltitle = {Comp. Part. Mech.},
	author = {Leonardi, Alessandro and Wittel, Falk K. and Mendoza, Miller and Herrmann, Hans J.},
	urldate = {2025-11-24},
	date = {2014-05},
	langid = {english},
	file = {PDF:C\:\\Users\\Paul Baselt\\Zotero\\storage\\8N947Z3W\\Leonardi et al. - 2014 - Coupled DEM-LBM method for the free-surface simulation of heterogeneous suspensions.pdf:application/pdf},
}
