% ============================================================================
% CHAPTER 3: METHODOLOGY AND EXPERIMENTAL DESIGN
% ============================================================================

\chapter{Methodology and Experimental Design}
\label{ch:methodology}

This chapter presents the methodological approach for predicting flow fields around settling crystals using UNet architectures. We first compare two fundamentally different approaches for velocity field prediction (\S\ref{sec:velocity_approaches}), then detail the experimental design (\S\ref{sec:experimental_design}), describe the physics-informed training strategy (\S\ref{sec:physics_informed}), and finally present the data augmentation techniques employed (\S\ref{sec:data_augmentation}).

% ============================================================================
\section{Velocity Prediction Approaches}
\label{sec:velocity_approaches}
% ============================================================================

Two fundamentally different approaches exist for predicting incompressible flow fields: direct velocity prediction and stream function formulation. This section compares both approaches and justifies the methodological choice for this thesis.

\subsection{Approach A: Direct Velocity Prediction}
\label{sec:direct_velocity}

The direct approach predicts velocity components $(v_x, v_z)$ directly from the phase field input (crystal positions):

\begin{equation}
\mathbf{u} = f_{\theta}(\phi) = (v_x, v_z)
\end{equation}

where $f_{\theta}$ is the UNet with parameters $\theta$ and $\phi$ is the phase field (0 = fluid, 1 = crystal).

\textbf{Loss function}: Combined data-driven and physics-informed loss:
\begin{equation}
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{MSE}} + \lambda \cdot \mathcal{L}_{\text{physics}}
\label{eq:loss_direct}
\end{equation}

where the physics loss enforces incompressibility as a soft constraint:
\begin{equation}
\mathcal{L}_{\text{physics}} = \mathcal{L}_{\text{div}} + \mathcal{L}_{\text{BC}}
\end{equation}

\textbf{Continuity constraint} (soft):
\begin{equation}
\mathcal{L}_{\text{div}} = \frac{1}{N_{\text{points}}} \sum_{i=1}^{N_{\text{points}}} \left(\frac{\partial v_x}{\partial x} + \frac{\partial v_z}{\partial z}\right)^2
\end{equation}

\textbf{Boundary condition constraint}:
\begin{equation}
\mathcal{L}_{\text{BC}} = \frac{1}{N_{\text{BC}}} \sum_{i \in \text{crystal}} \|\mathbf{u}(\mathbf{x}_i)\|^2
\end{equation}

\textbf{Advantages}:
\begin{itemize}
    \item Simple end-to-end architecture: single forward pass produces velocities
    \item Standard UNet implementation without modifications
    \item Direct optimization of target quantities
    \item Flexible: easy to add additional physics constraints
\end{itemize}

\textbf{Disadvantages}:
\begin{itemize}
    \item \textbf{No mathematical guarantee for mass conservation}: $\nabla \cdot \mathbf{u} = 0$ is only approximately satisfied
    \item Soft constraints can be violated during training
    \item Potential for unphysical flow fields, especially during extrapolation
    \item Requires careful balancing of loss terms (see \S\ref{sec:physics_informed})
\end{itemize}

\subsection{Approach B: Stream Function Formulation}
\label{sec:stream_function}

The stream function approach, inspired by Agarwal et al. \cite{agarwal2022}, predicts a scalar stream function $\psi$ from which velocities are derived through differentiation:

\begin{equation}
\psi = f_{\theta}(\phi)
\end{equation}

\begin{equation}
v_x = \frac{\partial \psi}{\partial z}, \quad v_z = -\frac{\partial \psi}{\partial x}
\label{eq:stream_function}
\end{equation}

\textbf{Mathematical foundation}: For 2D incompressible flow, the stream function automatically satisfies continuity:
\begin{equation}
\nabla \cdot \mathbf{u} = \frac{\partial v_x}{\partial x} + \frac{\partial v_z}{\partial z} = \frac{\partial^2 \psi}{\partial x \partial z} - \frac{\partial^2 \psi}{\partial z \partial x} = 0
\end{equation}

This holds by Schwarz's theorem (equality of mixed partial derivatives).

\textbf{Implementation}: The network outputs a single-channel stream function, with velocities computed via automatic differentiation:

\begin{lstlisting}[language=Julia, caption={Stream function velocity computation}]
function compute_velocities_from_stream(psi)
    # Automatic differentiation for spatial derivatives
    vx = gradient(psi, z)    # ∂ψ/∂z
    vz = -gradient(psi, x)   # -∂ψ/∂x
    return vx, vz
end
\end{lstlisting}

\textbf{Loss function}: Since mass conservation is automatically satisfied, the loss focuses on data fidelity and momentum conservation:
\begin{equation}
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{MSE}}(\mathbf{u}_{\text{pred}}, \mathbf{u}_{\text{true}}) + \lambda \cdot \mathcal{L}_{\text{momentum}}
\end{equation}

\textbf{Advantages}:
\begin{itemize}
    \item \textbf{Hard constraint on mass conservation}: $\nabla \cdot \mathbf{u} = 0$ is mathematically exact (up to machine precision)
    \item More physically consistent predictions
    \item Better suited for long-time integration (hybrid approaches)
    \item Demonstrated 89$\times$ speedup in mantle convection \cite{agarwal2022}
\end{itemize}

\textbf{Disadvantages}:
\begin{itemize}
    \item More complex implementation requiring automatic differentiation
    \item Additional computational cost from derivative operations
    \item Less direct optimization (predicting $\psi$ instead of target $\mathbf{u}$)
    \item Potential numerical instabilities in derivative computation
    \item More challenging boundary condition enforcement
\end{itemize}

\subsection{Approach Comparison and Selection}
\label{sec:approach_comparison}

Table~\ref{tab:approach_comparison} summarizes the key differences between both approaches:

\begin{table}[htbp]
\centering
\caption{Comparison of velocity prediction approaches}
\label{tab:approach_comparison}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Aspect} & \textbf{Direct Velocity} & \textbf{Stream Function} \\
\midrule
Mass conservation & Soft (loss term) & Hard (mathematical) \\
Implementation & Simple & Complex (AD required) \\
Output channels & 2 $(v_x, v_z)$ & 1 $(\psi)$ \\
Training stability & Standard & Requires careful tuning \\
Boundary conditions & Direct penalty & Indirect via $\psi$ \\
Physical guarantees & Approximate & Exact (continuity) \\
Computational cost & Lower & Higher (derivatives) \\
Extrapolation safety & Lower & Higher \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Methodological decision for this thesis}:

\textit{Primary approach}: \textbf{Direct velocity prediction} (Approach A) is used as the primary method for the following reasons:
\begin{enumerate}
    \item \textbf{Simplicity}: Enables rapid prototyping and experimentation with different architectures
    \item \textbf{Baseline establishment}: Provides clear baseline for generalization capability assessment
    \item \textbf{Interpretability}: Direct prediction of target quantities simplifies analysis
    \item \textbf{Precedent}: Widely used in physics-informed ML literature \cite{thuerey2020deep}
\end{enumerate}

\textit{Secondary investigation}: \textbf{Stream function approach} (Approach B) is implemented as a comparative study (see Chapter~\ref{ch:results}) to evaluate:
\begin{enumerate}
    \item Whether hard mass conservation improves generalization from 1 to $N$ crystals
    \item Impact on prediction accuracy for different crystal numbers
    \item Computational trade-offs (training time vs. physical consistency)
\end{enumerate}

This dual-approach strategy enables both methodological contribution (establishing baseline with standard approach) and scientific insight (evaluating impact of hard physical constraints on generalization).

% ============================================================================
\section{Experimental Design}
\label{sec:experimental_design}
% ============================================================================

The experimental design follows a systematic approach to evaluate generalization capability across different crystal numbers.

\subsection{Research Questions}

The experimental design addresses three core research questions:

\begin{enumerate}
    \item \textbf{RQ1 (Primary)}: Can a UNet trained on $N$ crystals accurately predict flow fields for 1 to $N$ crystals?
    \item \textbf{RQ2 (Methodological)}: Does the stream function approach improve generalization compared to direct velocity prediction?
    \item \textbf{RQ3 (Scaling)}: How does prediction accuracy degrade as the number of crystals approaches the training complexity $N$?
\end{enumerate}

\subsection{Training Strategy}

\textbf{Target complexity}: Models are trained on $N=10$ crystals as the baseline complexity. This choice balances:
\begin{itemize}
    \item Sufficient complexity to capture multi-body interactions (45 pairwise interactions)
    \item Computational feasibility for generating training data
    \item Realistic crystal concentrations for magmatic systems
\end{itemize}

\textbf{Training data composition}: Each training sample contains exactly $N=10$ crystals with:
\begin{itemize}
    \item Diverse spatial configurations (random positions with minimum separation)
    \item Variable crystal radii: $R \sim \mathcal{U}(0.03, 0.08)$ (normalized units)
    \item Variable density contrasts: $\Delta\rho \sim \mathcal{U}(150, 300)$ kg/m$^3$
    \item Fixed viscosity: $\mu = 10^{20}$ Pa·s (representative of magmatic systems)
\end{itemize}

\textbf{Dataset size}: 500 unique configurations generated via LaMEM simulations:
\begin{itemize}
    \item Training set: 400 samples (80\%)
    \item Validation set: 100 samples (20\%)
    \item Augmentation: $\sim$2$\times$ effective increase (see \S\ref{sec:data_augmentation})
\end{itemize}

\subsection{Evaluation Strategy}

\textbf{Systematic complexity testing}: After training on $N=10$ crystals, evaluate on:
\begin{itemize}
    \item Single crystal ($n=1$): Simplest case, isolated Stokes flow
    \item Two crystals ($n=2$): DKT interactions, qualitative benchmark
    \item Five crystals ($n=5$): Intermediate complexity
    \item Ten crystals ($n=10$): Training complexity (in-distribution)
\end{itemize}

For each complexity level, generate 50 new test configurations not seen during training.

\textbf{Metrics hierarchy}:
\begin{enumerate}
    \item \textbf{Primary}: Mean Absolute Error (MAE) on velocity fields
    \item \textbf{Physics}: Divergence error $\|\nabla \cdot \mathbf{u}\|$
    \item \textbf{Correlation}: Pearson correlation coefficient $\rho(\mathbf{u}_{\text{pred}}, \mathbf{u}_{\text{true}})$
    \item \textbf{Structural}: $R^2$ score for overall field similarity
\end{enumerate}

\subsection{Approach Comparison Protocol}

To address RQ2, both approaches (direct velocity and stream function) are trained and evaluated under identical conditions:

\begin{table}[htbp]
\centering
\caption{Controlled comparison protocol}
\label{tab:comparison_protocol}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Parameter} & \textbf{Direct Velocity} & \textbf{Stream Function} \\
\midrule
Architecture & UNet (2 outputs) & UNet (1 output + AD) \\
Training data & Identical 400 samples & Identical 400 samples \\
Augmentation & Same strategy & Same strategy \\
Epochs & 100 & 100 \\
Learning rate & $10^{-3}$ & $10^{-3}$ \\
Optimizer & Adam & Adam \\
Batch size & 8 & 8 \\
Physics loss weight & $\lambda = 0.1$ & $\lambda_{\text{momentum}} = 0.1$ \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Evaluation criteria}: For each crystal number $n \in \{1, 2, 5, 10\}$:
\begin{itemize}
    \item Compute MAE, divergence error, and correlation
    \item Visualize qualitative flow field predictions
    \item Compare computational cost (training time, inference time)
\end{itemize}

\textbf{Expected outcomes}:
\begin{itemize}
    \item Stream function should show lower divergence error (hard constraint)
    \item Direct velocity may show lower MAE (direct optimization)
    \item Generalization capability comparison reveals impact of physical constraints
\end{itemize}

% ============================================================================
\section{Physics-Informed Training}
\label{sec:physics_informed}
% ============================================================================

\subsection{Adaptive Loss Weighting}

Physical constraint integration uses an adaptive weighting strategy to balance data fidelity and physics compliance:

\begin{equation}
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{MSE}} + \lambda(t) \cdot \mathcal{L}_{\text{physics}}
\end{equation}

\textbf{Warm-up schedule}: The physics loss weight increases gradually to prevent training instability:

\begin{table}[htbp]
\centering
\caption{Adaptive weighting strategy for physics-informed loss}
\label{tab:lambda_schedule}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Training Phase} & \textbf{Epochs} & \textbf{$\lambda$ Value} \\
\midrule
Warm-up & 1--5 & 0.01 \\
Transition & 6--15 & 0.05 \\
Full Physics & 16+ & 0.10 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Rationale}: Early training focuses on learning approximate flow patterns from data. Physics constraints become more important once basic patterns are established, preventing the network from converging to unphysical local minima.

\subsection{Continuity Constraint Implementation}

For the direct velocity approach, the divergence constraint is computed via central finite differences:

\begin{lstlisting}[language=Julia, caption={GPU-compatible divergence computation}]
function compute_divergence(velocity_pred)
    vx = velocity_pred[:, :, 1, :]
    vz = velocity_pred[:, :, 2, :]
    
    # Central differences (second-order accurate)
    dvx_dx = (vx[3:end, :, :] - vx[1:end-2, :, :]) / (2 * dx)
    dvz_dz = (vz[:, 3:end, :] - vz[:, 1:end-2, :]) / (2 * dz)
    
    # Combine (interior points only)
    div = dvx_dx[2:end-1, :, :] + dvz_dz[:, 2:end-1, :]
    
    return mean(abs2.(div))
end
\end{lstlisting}

\textbf{Boundary treatment}: Divergence is computed only at interior points to avoid boundary artifacts. Boundaries are handled separately via $\mathcal{L}_{\text{BC}}$.

\subsection{Stream Function: Momentum Constraint}

For the stream function approach, since continuity is automatic, the physics loss enforces momentum balance:

\begin{equation}
\mathcal{L}_{\text{momentum}} = \frac{1}{N} \sum_{i=1}^{N} \left\|\nabla p - \mu \nabla^2 \mathbf{u}\right\|^2
\end{equation}

where $\nabla^2 \mathbf{u}$ is computed via automatic differentiation of the velocity field derived from $\psi$.

% ============================================================================
\section{Data Augmentation}
\label{sec:data_augmentation}
% ============================================================================

To improve generalization across spatial configurations, systematic data augmentation is implemented:

\subsection{Augmentation Strategies}

\textbf{1. Horizontal reflection} (50\% probability):
\begin{itemize}
    \item Phase field: Mirror along vertical axis
    \item Velocity field: Mirror $v_x$ with sign reversal, mirror $v_z$ unchanged
    \item Preserves physics: Flow remains valid under coordinate transformation
\end{itemize}

\textbf{2. Circular shift} (small translations):
\begin{itemize}
    \item Random shift: $\Delta x, \Delta z \sim \mathcal{U}(-5\%, +5\%)$ of domain size
    \item Wraps around boundaries (periodic-like behavior)
    \item Increases positional invariance
\end{itemize}

\textbf{3. No rotation or scaling}:
\begin{itemize}
    \item Gravity defines preferred direction (vertical)
    \item Crystal size variations already in dataset
    \item Rotation would violate physical setup
\end{itemize}

\subsection{Augmentation Impact}

\textbf{Effective dataset size}: 
\begin{equation}
N_{\text{effective}} = N_{\text{base}} \times (1 + p_{\text{flip}}) \times (1 + p_{\text{shift}}) \approx 400 \times 2.5 = 1000 \text{ samples}
\end{equation}

\textbf{Validation}: Augmentation is \textit{not} applied to validation/test sets to ensure unbiased evaluation.

\textbf{Implementation}: Augmentation is applied on-the-fly during training (random per epoch) rather than pre-computing, providing maximum diversity.

% ============================================================================
\section{Summary}
\label{sec:methodology_summary}
% ============================================================================

This chapter established the methodological framework:

\begin{enumerate}
    \item \textbf{Dual approach strategy}: Direct velocity prediction as primary method, stream function as comparative validation of hard physical constraints
    
    \item \textbf{Systematic evaluation}: Training on $N=10$ crystals, evaluation on 1, 2, 5, and 10 crystals to assess generalization
    
    \item \textbf{Physics-informed training}: Adaptive loss weighting balances data fidelity with physical constraints
    
    \item \textbf{Data augmentation}: Horizontal flips and shifts increase effective dataset size while preserving physics
\end{enumerate}

The next chapter (\ref{ch:implementation}) details the technical implementation of these methods in Julia with GPU acceleration.