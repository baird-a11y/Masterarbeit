=== TENSOR-DIMENSIONEN DEBUG ===

Teste 128x128 Dimensionen
  Start 128x128
  Nach Pool 1 64x64
  Nach Pool 2 32x32
  Nach Pool 3 16x16
  Nach Pool 4 8x8

Teste 256x256 Dimensionen
  Start 256x256
  Nach Pool 1 128x128
  Nach Pool 2 64x64
  Nach Pool 3 32x32
  Nach Pool 4 16x16

=== VERBESSERTE UNET-SPEICHER SIMULATION ===

Teste 64x64
  Layer 1 64x64, 1→32
    Memory 37.7 MB
    Nach Pool 32x32
  Layer 2 32x32, 32→64
    Memory 37.7 MB
    Nach Pool 16x16
  Layer 3 16x16, 64→128
    Memory 37.7 MB
    Nach Pool 8x8
  Layer 4 8x8, 128→256
    Memory 37.7 MB
  ✓ 64x64 erfolgreich getestet

Teste 128x128
  Layer 1 128x128, 1→32
    Memory 33.6 MB
    Nach Pool 64x64
  Layer 2 64x64, 32→64
    Memory 67.1 MB
    Nach Pool 32x32
  Layer 3 32x32, 64→128
    Memory 67.1 MB
    Nach Pool 16x16
  Layer 4 16x16, 128→256
    Memory 33.6 MB
  ✓ 128x128 erfolgreich getestet

Teste 256x256
  Layer 1 256x256, 1→32
    Memory 67.1 MB
    Nach Pool 128x128
  Layer 2 128x128, 32→64
    Memory 268.4 MB
    Nach Pool 64x64
  Layer 3 64x64, 64→128
    Memory 167.8 MB
    Nach Pool 32x32
  Layer 4 32x32, 128→256
    Memory 134.2 MB
  ✓ 256x256 erfolgreich getestet

Teste 512x512
  Layer 1 512x512, 1→32
    Memory 201.3 MB
    Nach Pool 256x256
  Layer 2 256x256, 32→64
    Memory 1006.6 MB
    Nach Pool 128x128
  Layer 3 128x128, 64→128
    Memory 604.0 MB
    Nach Pool 64x64
  Layer 4 64x64, 128→256
    Memory 436.2 MB
  ✓ 512x512 erfolgreich getestet

=== REALISTISCHE BATCH-GRÖSSEN ===

Teste 64x64
  Batch 1 ✓ (1128.8 MB)
  Batch 2 ✓ (1128.8 MB)
  Batch 4 ✓ (1128.8 MB)
  Batch 8 ✓ (1128.8 MB)
  → Empfohlen Batch-Größe 4 (sicher)
  → Maximum Batch-Größe 8 (riskant)

Teste 128x128
  Batch 1 ✓ (1128.8 MB)
  Batch 2 ✓ (1128.8 MB)
  Batch 4 ✓ (1128.8 MB)
  Batch 8 ✓ (1162.3 MB)
  → Empfohlen Batch-Größe 4 (sicher)
  → Maximum Batch-Größe 8 (riskant)

Teste 256x256
  Batch 1 ✓ (1162.3 MB)
  Batch 2 ✓ (1162.3 MB)
  Batch 4 ✓ (1195.9 MB)
  Batch 8 ✓ (1296.6 MB)
  → Empfohlen Batch-Größe 4 (sicher)
  → Maximum Batch-Größe 8 (riskant)

============================================================
ANGEPASSTE EMPFEHLUNGEN NACH cuDNN-ANALYSE
============================================================
EMPFOHLENE TRAININGS-KONFIGURATION

1. Auflösungen
   - Beginnen Sie mit 64x64 (sicher)
   - 128x128 nur mit Batch-Größe 1
   - 256x256 nur wenn absolut nötig, Batch-Größe 1

2. Batch-Größen (konservativ)
   - 64x64 Batch 2-4
   - 128x128 Batch 1-2
   - 256x256 Batch 1

3. UNet-Architektur anpassen
   - Weniger Pooling-Schritte für kleine Auflösungen
   - Adaptive Netzwerktiefe je nach Eingabeauflösung
   - Gradient Checkpointing für große Modelle

4. Trainings-Strategie
   - Mixed-Precision Training (Float16)
   - Gradient Accumulation statt große Batches
   - Regelmäßige Memory-Cleanups

5. Debugging
   - Immer mit kleinsten Parametern beginnen
   - Schrittweise erhöhen und Memory überwachen
   - Bei cuDNN-Fehlern Dimensionen prüfen
============================================================
