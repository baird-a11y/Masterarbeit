% ============================================================================
% CHAPTER 2: THEORETICAL FOUNDATIONS
% Focused theory section for Master's thesis (20-25 pages)
% ============================================================================

\chapter{Theoretical Foundations}
\label{ch:theory}

This chapter establishes the theoretical foundations necessary to understand the central challenge of this thesis: predicting multi-crystal sedimentation flows using machine learning. We first review the physics of crystal settling in Stokes flow regimes (\S\ref{sec:crystal_physics}), then examine how UNet architectures enable efficient flow field prediction (\S\ref{sec:unet}), discuss physics-informed training approaches (\S\ref{sec:pinns}), and finally analyze the fundamental generalization challenge when training on $N$ crystals and evaluating across the range from 1 to $N$ crystals (\S\ref{sec:generalization}).

% ============================================================================
\section{Physics of Crystal Sedimentation}
\label{sec:crystal_physics}
% ============================================================================

\subsection{Stokes Flow Fundamentals}

Crystal sedimentation in magmatic systems occurs at very low Reynolds numbers ($\text{Re} \ll 1$), placing the flow firmly in the Stokes regime where inertial effects are negligible compared to viscous forces. The governing equations reduce from the full Navier-Stokes equations to the Stokes equations:

\begin{align}
\mathbf{0} &= -\nabla p + \mu \nabla^2 \mathbf{u} \label{eq:stokes_momentum}\\
\nabla \cdot \mathbf{u} &= 0 \label{eq:stokes_continuity}
\end{align}

where $p$ is pressure, $\mu$ is dynamic viscosity, and $\mathbf{u} = (u, v)$ is the velocity field. The Reynolds number is defined as:

\begin{equation}
\text{Re} = \frac{\rho_f v_p D}{\mu}
\end{equation}

where $\rho_f$ is fluid density, $v_p$ is particle velocity, and $D$ is particle diameter. Magmatic systems typically exhibit $\text{Re} \sim 10^{-4}$ to $10^{-2}$ \cite{martin1988crystal,martin1989fluid}.

\textbf{Key physical parameters} for olivine crystals in basaltic magma:
\begin{itemize}
    \item Crystal density contrast: $\Delta\rho \sim 600$ kg/m$^3$
    \item Magma viscosity: $\mu \sim 10^1$ to $10^3$ PaÂ·s
    \item Crystal diameter: $D \sim 0.1$ to 10 mm
    \item Settling velocities: $v_s \sim 10^{-8}$ to $10^{-4}$ m/s
\end{itemize}

For an isolated spherical crystal, Stokes' law provides the terminal settling velocity:

\begin{equation}
v_s = \frac{1}{18} \cdot \frac{(\rho_p - \rho_f)}{\mu} \cdot g \cdot D^2
\label{eq:stokes_law}
\end{equation}

This velocity results from the balance of three forces: gravitational ($F_g = \frac{4}{3}\pi R^3 \rho_p g$), buoyancy ($F_b = \frac{4}{3}\pi R^3 \rho_f g$), and drag ($F_d = 6\pi\mu R v$).

\subsection{Multi-Particle Interactions and Collective Dynamics}

When multiple crystals are present, the flow field becomes significantly more complex due to hydrodynamic interactions. These interactions occur through two primary mechanisms:

\textbf{Far-field interactions} are described by the Oseen tensor, with velocity disturbances decaying as $1/r$ from each particle. While individually weak, these long-range effects become significant when many particles are present.

\textbf{Near-field lubrication forces} dominate when particles approach closely ($\delta \ll R$, where $\delta$ is the gap size). These forces scale approximately as $F \sim \mu V R/\delta$ and prevent direct particle contact while dramatically altering local flow patterns.

A particularly important collective phenomenon is the \textbf{drafting-kissing-tumbling (DKT) sequence} observed when two particles settle vertically \cite{fortes1987nonlinear}:

\begin{enumerate}
    \item \textbf{Drafting}: The trailing particle accelerates in the wake of the leading particle due to reduced drag
    \item \textbf{Kissing}: Particles approach closely, entering the lubrication regime
    \item \textbf{Tumbling}: Symmetry breaks, particles separate laterally and can exchange roles
\end{enumerate}

This DKT cycle serves as a critical validation benchmark for multi-particle simulations and demonstrates emergent behavior not predictable from single-particle physics alone.

\textbf{Hindered settling} occurs at higher particle concentrations, where the mean settling velocity decreases according to the Richardson-Zaki correlation \cite{happel1983low}:

\begin{equation}
\frac{v}{v_0} = (1-\phi)^n
\label{eq:richardson_zaki}
\end{equation}

where $\phi$ is the solid volume fraction and $n \approx 5$ to 6 for Stokes flow. At dilute concentrations ($\phi < 3\%$), Batchelor's theory gives:

\begin{equation}
\frac{v}{v_0} = 1 - 6.55\phi
\end{equation}

\subsection{Complexity Scaling with Crystal Number}

The transition from few to many crystals introduces several critical challenges:

\textbf{Interaction complexity scaling}: While systems with few crystals have limited interactions, $N$ crystals have $N(N-1)/2$ pairwise interactions. For 10 crystals, this represents 45 potential pairwise interactions, along with higher-order multi-body effects.

\textbf{Wake interference}: Individual crystal wakes can overlap and interact in complex ways, creating collective flow patterns that depend on the specific spatial configuration. At sufficient particle concentrations (Galileo number $\text{Ga} \geq 178$), clustering occurs with columnar structures forming and velocity enhancements up to 12\% \cite{uhlmann2014clustering}.

\textbf{Configuration sensitivity}: The spatial arrangement of crystals critically affects the dynamics. Vertical alignment promotes DKT behavior, while side-by-side arrangements lead to mutual repulsion. The challenge for machine learning is to capture these configuration-dependent phenomena across the full range from single crystals to the trained crystal number $N$.

% ============================================================================
\section{UNet Architecture for Flow Field Prediction}
\label{sec:unet}
% ============================================================================

% [This section would contain the UNet architecture details - to be written]

% ============================================================================
\section{Physics-Informed Neural Networks}
\label{sec:pinns}
% ============================================================================

% [This section would contain PINN details - to be written]

% ============================================================================
\section{The Generalization Challenge: Training on N Crystals, Evaluating on 1 to N}
\label{sec:generalization}
% ============================================================================

\subsection{The Fundamental Extrapolation Problem}

Machine learning models typically excel at \textbf{interpolation}---predicting within the training distribution---but struggle with \textbf{extrapolation}---predicting outside it. Neural networks are universal function approximators \textit{within the training domain}, but their behavior outside is unconstrained by training data.

The asymptotic behavior of neural networks outside the training regime is determined primarily by the activation functions (ReLU, sigmoid, tanh), not by the training data. This makes extrapolation fundamentally unreliable without additional constraints.

\textbf{Critical for this thesis}: When training on $N$ crystals and evaluating on systems with fewer crystals (1 to $N-1$), the network must learn to handle variable complexity, including the limiting cases of single-crystal physics. This requires the network to learn compositional rules that combine single-crystal and multi-crystal physics appropriately, rather than memorizing specific $N$-crystal configurations.

\subsection{Configuration Space and Variable Complexity}

The challenge becomes clear when examining how configuration space changes with crystal number:

\textbf{Single crystal}: 3 degrees of freedom (DOF)---position $(x, y)$ and radius $R$. The network must learn flow patterns for one obstacle in various positions and sizes.

\textbf{$N$ crystals}: $3N$ DOF---$N$ positions plus $N$ radii. The configuration space is $N$-dimensional and contains fundamentally different physics depending on the number of crystals present.

\textbf{Interaction complexity variation}:
\begin{itemize}
    \item 1 crystal: 0 interactions---isolated Stokes flow
    \item 2 crystals: 1 interaction (DKT potential)
    \item 5 crystals: 10 interactions
    \item 10 crystals: 45 interactions
\end{itemize}

When training on $N$ crystals, the network is exposed to configurations with up to $N(N-1)/2$ interactions. During evaluation on fewer crystals, it must correctly predict simpler scenarios with fewer interactions---effectively learning to "turn off" unnecessary complexity when crystals are absent.

\subsection{Compositional Generalization}

\textbf{Definition}: The ability to understand and produce novel combinations from known components in systematic, algebraic ways \cite{lake2023systematic}.

\textbf{The challenge for neural networks}:
\begin{itemize}
    \item Standard architectures lack explicit mechanisms for systematic composition
    \item Tend to memorize patterns rather than learning underlying rules
    \item Must learn to scale complexity appropriately based on the number of crystals present
\end{itemize}

\textbf{Successful approach} (Lake \& Baroni \cite{lake2023systematic}): Training on diverse compositional tasks enables systematic generalization even with standard architectures (transformers). Key insight: \textit{diversity of training tasks matters more than architecture}.

\textbf{Implication for this thesis}: Training on $N$ crystals with diverse spatial configurations and crystal properties may enable the network to learn the underlying compositional structure---how single-crystal flow fields combine to produce multi-crystal patterns. This should enable reliable prediction across the full range from 1 to $N$ crystals.

\subsection{Transfer Learning and Curriculum Learning}

Two complementary strategies address the generalization challenge:

\textbf{Transfer learning}: Pre-train on simpler data, fine-tune on target complexity \cite{pellegrin2022transfer}:
\begin{enumerate}
    \item Train UNet on abundant single-crystal configurations
    \item Fine-tune on intermediate crystal numbers (2--5 crystals)
    \item Fine-tune on target complexity ($N$ crystals)
\end{enumerate}

\textbf{Layer-wise adaptation}:
\begin{itemize}
    \item \textbf{Early layers}: Low-level features (edges, boundaries)---transfer well across crystal counts
    \item \textbf{Middle layers}: Mid-level features (individual wakes)---partially transferable
    \item \textbf{Late layers}: High-level features (multi-body interactions)---require adaptation to target complexity
\end{itemize}

Transfer learning has demonstrated 97.3\% performance improvement for physics-informed networks \cite{pellegrin2022transfer}, dramatically reducing data requirements for complex scenarios.

\textbf{Curriculum learning}: Progressive difficulty $1 \rightarrow 2 \rightarrow 5 \rightarrow N$ crystals during training. This helps the network learn the compositional structure by experiencing how complexity builds up incrementally.

\subsection{Domain Decomposition as Generalization Strategy}

Rana et al.'s \cite{rana2024scalable_cnn} domain decomposition approach (discussed in \S\ref{sec:unet}) provides another generalization mechanism:

Rather than learning ``$N$-crystal physics'' as a monolithic concept, decompose the problem into ``local 1--3 crystal physics'' applied repeatedly. The network learns:
\begin{itemize}
    \item Flow patterns around individual crystals and small groups
    \item How these patterns decay with distance (via LOVE metric decorrelation length)
    \item How to stitch local predictions into a global field
\end{itemize}

This reframes generalization from ``predict $N$-body configurations and all simpler cases'' to ``apply learned local physics at multiple locations''---a significantly easier problem.

\textbf{Key advantage}: Training data requirements scale with local subdomain complexity, not full-domain complexity. A model trained on local patches containing 1--3 crystals can handle up to $N$ crystals in the full domain without seeing all possible $N$-crystal configurations during training.

\subsection{Metrics for Evaluating Generalization}

To quantify generalization performance across different crystal numbers, we employ multiple metrics:

\textbf{Standard metrics}:
\begin{itemize}
    \item Mean Squared Error (MSE) and Mean Absolute Error (MAE) for velocity/pressure fields
    \item $R^2$ coefficient of determination
    \item Relative errors: $\|\mathbf{u}_{\text{pred}} - \mathbf{u}_{\text{true}}\| / \|\mathbf{u}_{\text{true}}\|$
\end{itemize}

\textbf{Physics-based metrics}:
\begin{itemize}
    \item Divergence error: $\|\nabla \cdot \mathbf{u}\|$ (should be $\approx 0$ everywhere)
    \item Boundary condition violations: $\|\mathbf{u}(\mathbf{x}_{\text{crystal}})\|$ at no-slip surfaces
    \item Momentum balance: Comparison of forces on crystals with hydrodynamic predictions
\end{itemize}

\textbf{Generalization-specific metrics}:
\begin{itemize}
    \item \textbf{Complexity scaling}: Performance variation from 1 crystal up to $N$ crystals
    \item \textbf{Transfer learning gain}: Improvement from pre-training versus training from scratch on $N$ crystals
    \item \textbf{Systematic generalization tests}: Novel spatial arrangements not seen during training
\end{itemize}

\textbf{Benchmark validation}:
\begin{itemize}
    \item DKT sequence for 2 crystals (qualitative behavior check)
    \item Richardson-Zaki hindered settling for multiple crystals (quantitative scaling)
    \item Comparison with high-fidelity LBM-DEM simulations
\end{itemize}

\subsection{Theoretical Bounds and Expectations}

Based on the literature review, we can establish theoretical expectations for generalization performance:

\textbf{With purely data-driven training on $N$ crystals}: The network should interpolate well within the $N$-crystal configuration space, but may struggle with simpler cases (1--$N-1$ crystals) if these are underrepresented or absent in training data. Risk of overfitting to $N$-crystal complexity.

\textbf{With physics-informed constraints}: Enforcing $\nabla \cdot \mathbf{u} = 0$ and boundary conditions should maintain physical plausibility across all crystal numbers, preventing the network from producing unphysical flow fields when fewer crystals are present.

\textbf{With transfer learning}: Starting from pre-trained single-crystal knowledge and progressively adding complexity should enable better handling of the full 1--$N$ crystal range. The 97\% boost demonstrated by Pellegrin et al. \cite{pellegrin2022transfer} suggests this is a promising strategy.

\textbf{With domain decomposition}: Focusing on local flow physics rather than global configuration should enable the network to handle any number of crystals up to $N$ by applying learned local rules repeatedly.

\textbf{With hybrid approach} (physics-informed + transfer + domain decomposition): This combination should provide the most robust generalization across the full crystal number range, and is the approach adopted in this thesis (see Chapter~\ref{ch:methodology}).

% ============================================================================
\section{Summary}
\label{sec:theory_summary}
% ============================================================================

This chapter established four theoretical pillars for the thesis:

\begin{enumerate}
    \item \textbf{Crystal sedimentation physics} (\S\ref{sec:crystal_physics}): Stokes flow regime ($\text{Re} \ll 1$) enables linear superposition principles, but $N$-body effects emerge from collective hydrodynamic coupling. Multi-particle interactions scale quadratically with crystal count, introducing configuration-dependent complexity.

    \item \textbf{UNet architecture} (\S\ref{sec:unet}): The encoder-decoder structure with skip connections is ideally suited for flow field prediction, capturing multi-scale phenomena while preserving sharp spatial features. Rana et al.'s \cite{rana2024scalable_cnn} domain decomposition approach provides direct precedent for handling variable numbers of obstacles.

    \item \textbf{Physics-informed training} (\S\ref{sec:pinns}): Incorporating physical constraints (continuity equation, boundary conditions) into the loss function improves data efficiency and ensures physical plausibility across different crystal numbers. For Stokes flow, this is particularly tractable due to equation linearity.

    \item \textbf{Generalization challenge} (\S\ref{sec:generalization}): Training on $N$ crystals and evaluating on 1--$N$ crystals requires the network to learn compositional rules that appropriately scale complexity with crystal number. Transfer learning, curriculum learning, and domain decomposition provide complementary strategies to address this challenge.
\end{enumerate}

The methodology in Chapter~\ref{ch:methodology} combines these theoretical insights into a hybrid approach: physics-informed gated residual UNet trained through curriculum learning with potential domain decomposition. This combination leverages each strategy's strengths while enabling robust generalization across the full range of crystal numbers from 1 to $N$.